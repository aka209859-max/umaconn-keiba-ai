# 位置指数の枠順係数に関する学術的ディープサーチプロンプト

## 📋 Executive Summary

地方競馬（NAR）のスピード指数において、**位置指数**は馬の位置取り能力を評価する重要な指標です。

現在、**枠順係数の算出方法**について、実データに基づく単純な平均的中率差分方式を採用していますが、**学術的・統計学的・数学的な観点**から、より高精度な算出方法を検討する必要があります。

---

## 🎯 現状の実装と課題

### **1. 現行実装（2026-01-10時点）**

#### **計算式**
```
枠順係数 = (平均的中率 - 基準値) × スケール係数

ここで、
- 平均的中率 = (単勝的中率 + 複勝的中率) / 2
- 基準値 = 各競馬場×距離の全枠平均的中率
- スケール係数 = 1.5（固定値）
```

#### **実装例**
| 競馬場 | 距離 | 枠 | 単勝的中率 | 複勝的中率 | 平均的中率 | 基準値 | 枠順係数 |
|--------|------|-----|-----------|-----------|-----------|--------|---------|
| 門別 | 1000m | 1番 | 8.97% | 26.34% | 17.66% | 20.05% | **-3.59** |
| 門別 | 1000m | 8番 | 10.43% | 30.93% | 20.68% | 20.05% | **+0.95** |
| 船橋 | 2400m | 1番 | - | - | 50.00% | 17.38% | **+48.93** |
| 金沢 | 2000m | 2番 | - | - | 5.21% | 17.30% | **-18.14** |

### **2. 現行方式の課題**

#### **課題A: 統計的有意性の欠如**
- サンプル数の違い（n=195 vs n=6,208）が考慮されていない
- 信頼区間が算出されていない
- 偶然の偏りと真の有利/不利の区別ができない

#### **課題B: 単純な線形スケーリング**
- スケール係数（1.5）が固定値であり、競馬場や距離によって調整されていない
- 的中率差と実際の指数影響が線形関係にあるという仮定が検証されていない

#### **課題C: 外れ値の影響**
- 極端な値（+48.93, -18.14）が統計的に妥当かどうか不明
- サンプル数が少ない場合の信頼性が低い

#### **課題D: 単勝と複勝の重み付け**
- 単純な算術平均（50:50）が最適かどうか不明
- 予測対象（単勝/複勝/馬連等）によって最適な重み付けが異なる可能性

---

## 🔬 学術的・統計学的な最適化アプローチ

### **アプローチ1: ベイズ統計による信頼区間付き推定**

#### **理論的背景**
- 各枠の的中率をベイズ推定により算出
- サンプル数が少ない場合は、事前分布により全体平均に近づける（縮小推定）
- 信頼区間を算出し、統計的に有意な係数のみを採用

#### **数学的モデル**
```
θ_i ~ Beta(α + k_i, β + n_i - k_i)

ここで、
- θ_i: 枠iの真の的中率（事後分布）
- k_i: 枠iの的中数
- n_i: 枠iのサンプル数
- α, β: 事前分布のパラメータ（全体平均から推定）
```

#### **枠順係数の算出**
```
枠順係数_i = (E[θ_i] - E[θ_baseline]) × スケール係数

ここで、
- E[θ_i]: 枠iの事後期待値
- E[θ_baseline]: 基準枠（全枠平均）の事後期待値
```

---

### **アプローチ2: 一般化線形モデル（GLM）による多変量解析**

#### **理論的背景**
- 枠順の影響を、他の要因（距離、競馬場、馬場状態等）と同時に推定
- ロジスティック回帰により、的中率と説明変数の関係をモデル化
- 交互作用項を導入し、競馬場×距離×枠の複雑な関係を表現

#### **数学的モデル**
```
logit(P(win)) = β_0 + β_1 × wakuban + β_2 × kyori + β_3 × keibajo
                + β_4 × (wakuban × kyori) + β_5 × (wakuban × keibajo)
                + ... + ε

ここで、
- P(win): 的中確率
- wakuban: 枠番（1-8）
- kyori: 距離（m）
- keibajo: 競馬場（ダミー変数）
- β_i: 回帰係数（統計的に推定）
- ε: 誤差項
```

#### **枠順係数の算出**
```
枠順係数_i = β_1 + β_4 × kyori + β_5 × keibajo_dummy

※ 各競馬場×距離に応じて動的に算出
```

---

### **アプローチ3: 機械学習による非線形モデル**

#### **理論的背景**
- XGBoost、LightGBM等の勾配ブースティングモデルを使用
- 枠順の影響を非線形に推定
- SHAP値により、各特徴量の寄与度を定量化

#### **特徴量設計**
```
- wakuban（1-8）
- kyori（距離）
- keibajo_code（競馬場コード）
- tosu（出走頭数）
- baba_code（馬場状態）
- 交互作用項（wakuban × kyori, wakuban × tosu 等）
```

#### **枠順係数の算出**
```
枠順係数_i = SHAP_value(wakuban=i) × スケール係数

※ SHAP値により、枠番iが予測に与える影響を定量化
```

---

### **アプローチ4: エンピリカルベイズによる縮小推定**

#### **理論的背景**
- James-Stein推定量による縮小推定
- サンプル数が少ない場合、全体平均に近づける
- サンプル数が多い場合、観測値に近づける

#### **数学的モデル**
```
θ̂_i = (1 - B) × 全体平均 + B × 観測値

ここで、
- B = max(0, 1 - (k - 3) × σ²_全体 / Σ(θ_i - 全体平均)²)
- k: 枠番の数（通常8）
- σ²_全体: 全体分散
```

---

## 📊 添付資料の要求事項

### **必須データ**
1. **枠順別的中率データ**（既に取得済み）
   - ファイル: `data-1768033229370.csv`
   - 内容: 全競馬場×距離×枠番別の単勝/複勝的中率

2. **レース結果の詳細データ（できれば）**
   - 各レースの枠番、着順、距離、競馬場、馬場状態等
   - サンプル数: 最低1,000レース以上（理想は10,000レース以上）

3. **現行の位置指数算出コード**
   - ファイル: `core/index_calculator.py` (行390-441: calculate_position_index)

### **追加で必要な資料**
- 競馬場のコース形状データ（直線距離、コーナー数等）
- 過去の予測精度データ（もしあれば）
- 中央競馬（JRA）の枠順係数に関する研究論文（もしあれば）

---

## 🔍 ディープサーチのための質問（WebSearch用）

### **質問1: ベイズ統計による枠順係数の推定**
```
競馬の枠順有利不利をベイズ統計で推定する方法は？
サンプル数が少ない場合の信頼区間付き推定の手法は？
Beta分布を用いた的中率の事後推定の実装例は？
```

### **質問2: 一般化線形モデル（GLM）の適用**
```
競馬の予測モデルにおける一般化線形モデル（GLM）の適用事例は？
ロジスティック回帰で枠順の影響を推定する場合の注意点は？
交互作用項（枠×距離、枠×競馬場）の導入による精度向上の効果は？
```

### **質問3: 機械学習による枠順係数の推定**
```
競馬予測におけるXGBoost、LightGBMの活用事例は？
SHAP値により枠順の寄与度を定量化する方法は？
特徴量エンジニアリング（交互作用項、非線形変換）のベストプラクティスは？
```

### **質問4: エンピリカルベイズによる縮小推定**
```
James-Stein推定量による縮小推定の理論と実装は？
野球の打率推定における縮小推定の応用事例は？（競馬への応用可能性）
サンプル数が不均一な場合の縮小推定の最適化手法は？
```

### **質問5: 学術論文と実証研究**
```
競馬の枠順有利不利に関する統計学的研究論文は？（特に2020年以降）
地方競馬（NAR）とJRAで枠順の影響は異なるか？
ダート競馬における枠順の影響に関する実証研究は？
```

---

## 📈 評価指標

各アプローチの有効性を以下の指標で評価します。

### **1. 統計的有意性**
- p値 < 0.05（5%有意水準）
- 信頼区間が0を含まない
- ベイズファクター > 3（ベイズ統計の場合）

### **2. 予測精度**
- 単勝的中率（現行 vs 改善後）
- 複勝的中率（現行 vs 改善後）
- 回収率（現行 vs 改善後）

### **3. モデルの解釈性**
- 係数の意味が明確か？
- CEOが理解・説明できるか？
- 実装が容易か？

### **4. 汎化性能**
- 訓練データとテストデータで精度が一致するか？
- 過学習（オーバーフィッティング）していないか？
- 新しいレースに対して頑健か？

---

## 🚀 実装ロードマップ

### **Phase 1: ベイズ統計による推定（推奨: 最初に実装）**
- 理由: 統計的に最も堅牢で、解釈性も高い
- 実装時間: 1-2時間
- 必要なライブラリ: `scipy`, `numpy`, `pandas`

### **Phase 2: 一般化線形モデル（GLM）による推定**
- 理由: 多変量解析により、他の要因との交互作用を考慮
- 実装時間: 2-3時間
- 必要なライブラリ: `statsmodels`, `scikit-learn`

### **Phase 3: 機械学習による非線形モデル**
- 理由: 最高精度が期待できるが、解釈性は低い
- 実装時間: 3-5時間
- 必要なライブラリ: `xgboost`, `lightgbm`, `shap`

### **Phase 4: エンピリカルベイズによる縮小推定**
- 理由: サンプル数が不均一な場合に特に有効
- 実装時間: 1-2時間
- 必要なライブラリ: `numpy`, `scipy`

---

## 📊 期待される成果

### **定量的な改善**
- 枠順係数の信頼区間を算出（例: 95%信頼区間）
- サンプル数が少ない場合の過大評価を防止
- 予測精度の向上（単勝的中率 +1-3%、回収率 +5-10%）

### **定性的な改善**
- 統計的に有意な係数のみを採用（ノイズの除去）
- 競馬場×距離に応じた動的な係数算出
- 学術的根拠のある手法により、説明責任が向上

---

## 📚 参考文献（検索対象）

### **統計学**
- "Empirical Bayes Methods for Combining Likelihoods" (Bradley Efron, 1996)
- "The James-Stein Estimator" (Charles Stein, 1956)
- "Bayesian Data Analysis" (Andrew Gelman et al., 2013)

### **競馬予測**
- "競馬における枠順の有利不利に関する統計的分析"（学術論文を検索）
- "機械学習による競馬予測モデルの構築"（学術論文を検索）
- "Predicting Horse Racing Results Using Machine Learning" (海外論文を検索)

### **関連分野（野球の打率推定等）**
- "Shrinkage Estimation of Batting Averages" (統計学における縮小推定の応用)
- "Bayesian Hierarchical Models in Sports Analytics"

---

## ✅ 完了条件

以下の成果物が得られた時点で、ディープサーチ完了とします。

1. **WebSearch結果レポート**
   - 各アプローチの理論的根拠と実証研究
   - 学術論文からのエビデンス

2. **実装コードとテスト結果**
   - Phase 1（ベイズ統計）の実装と検証
   - 信頼区間付き枠順係数テーブルの生成

3. **予測精度の比較**
   - 現行方式 vs 新方式の的中率・回収率の比較
   - 統計的有意性検定の結果

4. **最終推奨方式の選定**
   - CEOが承認する最適なアプローチの決定
   - 実装ガイドラインとドキュメント

---

## 🎯 CEO への依頼事項

### **1. データの追加提供（可能であれば）**
以下のデータがあれば、より高精度な分析が可能です。

- **レース結果の詳細データ**（CSV or DB）
  - カラム: `race_id`, `wakuban`, `chakujun`, `kyori`, `keibajo_code`, `baba_code`, `tosu` 等
  - 期間: 2020年1月〜2025年12月（最低3年分）
  - サンプル数: 最低10,000レース以上

- **競馬場のコース情報**
  - 直線距離、コーナー数、コース形状（逃げ有利/差し有利 等）

### **2. 優先順位の決定**
以下の4つのアプローチのうち、どれを優先しますか？

- **A) ベイズ統計（推奨）**: 統計的に堅牢で、解釈性も高い
- **B) 一般化線形モデル（GLM）**: 多変量解析により精度向上
- **C) 機械学習（XGBoost/LightGBM）**: 最高精度が期待できるが、解釈性は低い
- **D) エンピリカルベイズ**: サンプル数が不均一な場合に有効

**推奨**: まず **A) ベイズ統計** を実装し、精度を確認してから B/C/D を検討

---

**Play to Win! 🚀**
