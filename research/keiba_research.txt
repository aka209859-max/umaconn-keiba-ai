次世代競馬予測システム RGS 1.0 / HQS (AAS) 高度化に向けた包括的研究レポート：AIトレンド、数理モデル、競合ベンチマークの徹底分析と対楽天戦略
1. エグゼクティブサマリー
本レポートは、競馬予測システム RGS 1.0 / HQS (AAS) の抜本的な性能向上と、市場の支配的プレイヤーである「楽天AI」および既存の競合サービス（netkeiba AI等）を凌駕するための戦略を提示するものである。2024年から2025年にかけた最新の学術論文、業界動向、および競合のベンチマーク結果を包括的に分析した結果、従来の勾配ブースティング木（GBDT）に依存したアプローチだけでは、効率化が進む現代の競馬予想市場において持続的な超過収益（Alpha）を生み出すことは困難であることが判明した。
分析の結果、RGS 1.0 が採るべき進化の方向性は以下の3点に集約される。
 * マルチモーダル・トランスフォーマーへの移行: 表形式データ（Tabular Data）の処理において、GBDTからTabTransformerやFT-Transformerといった最新の深層学習アーキテクチャへの移行、および映像データ（コンピュータビジョン）やテキストデータ（LLMによる厩舎コメント分析）を統合するマルチモーダル化が不可欠である。
 * ベイズ統計に基づく確率的厳密性の追求: レーティングシステムにおける「Whole-History Rating (WHR)」の導入、および小サンプルデータに対する「経験的ベイズ縮小推定量（Empirical Bayes Shrinkage）」の適用により、予測のロバスト性を飛躍的に高める必要がある。また、特徴量正規化においては、外れ値に脆弱なZスコアを廃し、Tanh推定量を標準とすべきである。
 * 動的資金管理とゲーム理論の実装: 予測精度（Accuracy）の向上のみならず、ケリー基準（Fractional Kelly）を用いた資金管理の最適化と、オッズ変動を織り込んだ強化学習（RL）による「賭け」そのものの最適化（Control Problem）へと課題設定をシフトする必要がある。
本レポートでは、これらの要素を詳細に論じ、楽天AIが強みとする「ビッグデータ・レコメンデーション」アプローチに対し、RGS 1.0 は「生体力学的・ゲーム理論的深化（Deep Specialist）」アプローチで対抗するための具体的なロードマップを提示する。
2. テーマ1：AIトレンドと予測モデルのパラダイムシフト（2024-2025）
競馬予測における機械学習の適用は、過去10年間で飛躍的な進化を遂げた。2024-2025年の最新トレンドは、単なる「着順予測」から、レース展開や馬の生体力学的状態を含む「コンテキスト理解」へと焦点が移っている。
2.1 GBDTの限界とTabular Transformersの台頭
2.1.1 業界標準としてのGBDT
現在、競馬予測の現場で最も広く使われているアルゴリズムは、LightGBM、XGBoost、CatBoostなどの勾配ブースティング決定木（GBDT）である 。これらは、欠損値の扱いや非線形性のモデリングに優れ、特に日本の競馬データのような不均質でノイズの多いテーブルデータに対して高い親和性を持つ。最近の研究でも、70万レース以上の大規模データセットを用いた実験において、CatBoostが従来の線形回帰や単純なニューラルネットワークと比較して、走破タイムの予測誤差をマイクロ秒単位まで削減できることが示されている 。
2.1.2 Transformerによる「相互作用」のモデリング
しかし、GBDTには致命的な弱点がある。それは、各行（各馬）を独立したサンプルとして学習するため、レース内での「馬同士の相互作用」を直接的にモデル化することが難しい点である。
2024年の研究トレンドは、自然言語処理で革命を起こしたTransformerアーキテクチャをテーブルデータに応用する「Tabular Transformers」（例：FT-Transformer, TabPFN）への移行を示唆している 。これらのモデルは「Self-Attention（自己注意機構）」を用いることで、同一レースに出走する競合馬のデータ（逃げ馬の有無、先行争いの激化など）をコンテキストとして取り込み、動的に予測を調整することが可能である。
また、GBDTとTransformerを組み合わせ、Transformerの予測残差をGBDTが学習するハイブリッドモデルの手法も提案されており、これにより解釈性と精度の両立が図られている 。RGS 1.0 においては、単一のLightGBMモデルから、Transformerを組み込んだアンサンブル学習へと移行することが、楽天AIを超えるための第一歩となる。
2.2 マルチモーダル学習：非人間中心的AI（Non-Anthropocentric AI）
文献調査から得られた最も重要な洞察の一つは、「非人間中心的AI（Non-Anthropocentric AI）」という概念である 。従来の予想は、人間が重要だと判断した指標（走破タイム、上がり3ハロン、馬体重）に依存していた（人間中心的）。しかし、最新のAIトレンドは、人間が知覚できない、あるいは数値化できていない情報を活用する方向へ進んでいる。
2.2.1 コンピュータビジョン（CV）による生体運動解析
RGS 1.0 が楽天AIに対して差別化を図れる最大の領域は、レース映像やパドック映像の解析である。
 * ストライド解析: 高フレームレートの映像から、馬のストライド周波数（ピッチ）とストライド長を計測する。レースの後半でストライドがどのように変化するか（バテてピッチが落ちるのか、ストライドが縮むのか）は、スタミナと余力を測る直接的な指標となる 。
 * 姿勢推定と感情分析: パドックでの馬の耳の向き、首の高さ、発汗量などをCVで解析し、「気性ベクトル（Temperament Vector）」を生成する。これにより、数値データには表れない「入れ込み」や「体調不良」を検知する。
 * オクルージョンへの対応: レース映像では馬群が重なり合う（オクルージョン）問題があるが、最新の姿勢推定モデルはこれを克服しつつあり、各馬の正確なトラジェクトリ（走行軌跡）と距離ロスを算出可能にしている 。
2.2.2 テキストマイニングとLLM
楽天技術研究所（RIT）は自然言語処理（NLP）に強みを持つが 、RGS 1.0 もまた、大規模言語モデル（LLM）を活用して厩舎コメントやトラックマンの短評をベクトル化し、特徴量として組み込むべきである。特に「弱気なコメント」や「定型文から外れた表現」は、オッズに織り込まれていないインサイダー情報に近いシグナルを含んでいる可能性がある。
2.3 強化学習とエージェントベースシミュレーション
予測（Prediction）と意思決定（Decision Making）は別物である。最新の研究では、競馬予測を「教師あり学習」ではなく「強化学習（Reinforcement Learning: RL）」の問題として捉え直す動きがある。
2.3.1 エージェントベースモデリング（ABM）
ブリストル大学の研究チームは、「Bristol Betting Exchange」と呼ばれるシミュレーション環境において、XGBoostを用いたエージェントが、他の単純なエージェント（ゼロ・インテリジェンス・エージェント）との取引を通じて、収益性の高い動的なベッティング戦略を学習できることを示した 。
これは、過去のレース結果をただ学習するのではなく、数百万回の仮想レースとベッティング市場のシミュレーションを行い、「どのような状況で、どのタイミングで、いくら賭けるのが最適か」という方策（Policy）を学習するアプローチである。
2.3.2 目的関数の変革
従来のモデルは LogLoss（確率の正確さ）や RMSE（着順の誤差）を最小化するように訓練されていた。しかし、RLのアプローチでは、ポートフォリオの収益率やシャープレシオを直接最大化するような損失関数（Loss Function）を設計することが可能である 。これにより、「的中率は低いが、当たれば大きく儲かる」ような、人間には実行困難な戦略をAIが自律的に獲得できる。
2.4 ドメイン適応：JRAからNARへの知見転移
日本特有の課題として、中央競馬（JRA）と地方競馬（NAR）のデータ質の格差がある。JRAはデータが豊富で質も高いが、NARはレース映像の画質が悪く、データ欠損も多い。
ここで重要となるのが「転移学習（Transfer Learning）」および「ドメイン適応（Domain Adaptation）」である 。
 * 手法: JRAのデータを「ソースドメイン」、NARのデータを「ターゲットドメイン」と定義し、両者の特徴量分布（周辺分布）を調整（アライメント）することで、JRAで学習した「馬の疲労メカニズム」や「騎手の戦略パターン」といった汎用的な知識を、データが少ないNARのレース予測に応用する。
 * 戦略的価値: 楽天AIなどの大手プレイヤーはJRAにリソースを集中させる傾向があるため、ドメイン適応を用いてNAR（特に南関東以外の地方競馬）の非効率な市場を攻略することは、RGS 1.0 にとって大きな収益機会（ブルーオーシャン）となる。
3. テーマ2：計算式比較と数理モデルの高度化
AIモデルに入力するデータの「質」を高め、出力された確率を「正しく」扱うためには、高度な数理モデルが不可欠である。ここでは、レーティング、正規化、縮小推定、資金管理における具体的な計算式を比較・検証する。
3.1 レーティングシステムの刷新：EloからWHRへ
3.1.1 Eloレーティングの限界
チェスで開発されたEloレーティングは、以下の式で更新される。
$$R_a' = R_a + K(S_a - E_a)$$ここで期待勝率 E_a は通常、以下のロジスティック曲線で計算される。

この「400」という除数は、レーティング差200ポイントが勝率約76%に対応するように設定された、チェス特有の歴史的定数であり、競馬の分散（分散がチェスより遥かに大きい）には本来適していない 。また、Eloは「現在の能力」のみを保持し、過去のパフォーマンス情報を逐次的に捨ててしまうため、成長期の3歳馬や衰退期の古馬の能力変化を捉えるのにラグ（遅延）が生じる。
3.1.2 Whole-History Rating (WHR) の優位性
RGS 1.0 が採用すべきは「Whole-History Rating (WHR)」である 。WHRは、ベイズ推定に基づき、過去の全対戦履歴から、各時点におけるプレイヤー（馬）の能力値を事後確率最大化（MAP推定）によって一括して算出する。
 * 特徴: 馬の能力を時間 t の関数 r(t) としてモデル化し、ブラウン運動のような確率過程として扱う。
 * メリット: 直近のレースだけでなく、デビュー戦からの全履歴と、対戦相手のその後の成績（例：新馬戦で負かした相手が後に重賞を勝った場合、過去の勝利の価値が上方修正される）を考慮できるため、能力評価の精度が格段に向上する。
3.2 不確実性の制御：ベイズ縮小推定量（Bayesian Shrinkage）
競馬データ、特に騎手や調教師の勝率は、試行回数（レース数）の差によって信頼性が大きく異なる。「1戦1勝（勝率100%）」の新人騎手と、「1000戦100勝（勝率10%）」のベテラン騎手をどう比較するかは、予測モデルの性能に直結する。
3.2.1 経験的ベイズ縮小の計算式
RGS 1.0 では、以下の縮小推定量を導入し、小サンプルの外れ値を補正すべきである 。
ここで：
 * \hat{\theta}_{MLE}：観測された勝率（最尤推定値）。
 * \mu：集団全体の平均勝率（事前分布の平均）。
 * B：縮小係数（Shrinkage Factor）。B = \frac{\sigma^2}{\sigma^2 + \tau^2} で定義される。
   * \sigma^2：個別の推定値の分散（サンプルサイズが小さいほど大きくなる）。
   * \tau^2：集団全体の分散（事前分布の分散）。
この式により、サンプルサイズが小さい（\sigma^2が大きい）場合、Bは1に近づき、推定値は全体平均 \mu に強く引き寄せられる（縮小される）。逆にサンプルサイズが十分にあれば、Bは0に近づき、個人の実績値が尊重される。
研究によると、ブートストラップ法（500回程度の再サンプリング）を用いて縮小係数を推定することで、予測モデルのMSE（平均二乗誤差）を有意に低減できることが示されている 。これは特に、出走回数の少ない地方馬や新人騎手の評価において、楽天AIに対する優位性となり得る。
3.3 特徴量正規化：ZスコアからTanh推定量へ
賞金、着差、オッズなどの競馬データは、正規分布ではなく、裾の重い分布（べき乗則など）に従うことが多い。
3.3.1 Zスコアの弊害
一般的なZスコア正規化（z = \frac{x - \mu}{\sigma}）は、データがガウス分布に従うことを前提としている。しかし、G1レースの超高額賞金や、大差負けのタイム差といった「外れ値」が存在すると、平均 \mu と標準偏差 \sigma が外れ値に引きずられて大きくなり、結果として大部分の「普通のデータ」がゼロ付近の狭い範囲に押し潰されてしまう 。これにより、モデルは普通の馬同士の微妙な能力差を学習できなくなる。
3.3.2 Tanh推定量の導入
RGS 1.0 では、外れ値にロバストな「Tanh推定量（Tanh Estimators）」を採用すべきである 。
ここで、平均と標準偏差の代わりに、ロバストな統計量である中央値（Median）と中央絶対偏差（MAD: Median Absolute Deviation）を使用する。
この変換により、データは (0, 1) の範囲に収められ、外れ値の影響を緩和しつつ、分布の中心付近のデータの解像度を保つことができる。これは、ニューラルネットワークの学習効率と収束速度を劇的に改善する。
3.4 資金管理の数理：ケリー基準の最適化
予測確率が正確であっても、賭け金の配分（ステーキング）を誤れば破産する。ここで重要なのが「ケリー基準」である。
3.4.1 ケリーの公式
資産の幾何平均成長率を最大化する賭け金の比率 f^* は以下の式で与えられる 。
 * b：オッズ（デシマルオッズ - 1）。
 * p：勝率。
 * q：敗率（1-p）。
3.4.2 フラクショナル・ケリーの実践
理論上はフル・ケリー（f^*）が最強だが、現実には「モデルの予測確率 p に誤差がある」ため、フル・ケリーは破産リスク（ドローダウン）が極めて高い。
RGS 1.0 では、フラクショナル・ケリー（Fractional Kelly）、具体的には 0.2倍から0.3倍のケリー基準（0.2f - 0.3f） を採用すべきである。シミュレーション研究によれば、ハーフ・ケリー（0.5f）以下に抑えることで、資産成長率の90%以上を維持しつつ、ボラティリティ（資産変動の激しさ）を50%以上削減できることが示されている 。
また、同一レース内の複数の馬に賭ける場合（排反事象）は、単純なケリー基準ではなく、相互の相関を考慮した多変量ケリー基準への拡張が必要である 。
4. テーマ3：競合ベンチマークと市場インテリジェンス
RGS 1.0 のポジショニングを明確にするため、主要な競合プレイヤーの戦略とパフォーマンスを詳細に分析する。
4.1 netkeiba「AI競馬予想マスターズ」の分析
netkeibaが主催するAIコンペティションの結果は、現在の日本におけるAI予測の最高到達点を示している 。
4.1.1 トップエージェントの戦略分析
| エージェント名 | ステージ1回収率 | ステージ2回収率 | 主な戦略・特徴 |
|---|---|---|---|
| Team BRAINS | 280.10% | -- | ディープラーニング活用（専門学校卒業生チーム）。特定のレース条件に特化し、高配当を狙い撃つ高ボラティリティ戦略。的中率も57.14%と高い。 |
| Yabusame | 231.43% | 99.85% | 払戻金総額1位。期待値（EV）重視で、単勝オッズ20倍〜100倍の穴馬を主戦場とする。大会ルール（脱落回避）に合わせて的中率重視にシフトする柔軟性を持つ。 |
| ぽんこつAI | 127.59% | 104.54% | 安定して100%超えを維持。**3連単（Trifecta）**に特化しており、単なる勝敗予測ではなく「着順の並び」を学習している（Listwise Ranking）。 |
| 匠のAI（Shosai AI） | -- | 180.16% | ステージ2で圧倒的な成績。詳細非公開だが、環境変化への適応力が高い。 |
4.1.2 洞察：ROIと的中率のトレードオフ
YabusameやTeam BRAINSの驚異的な回収率（200%超）は、堅実な本命党の戦略では達成不可能である。彼らは、一般の大衆が過小評価する「オッズ20倍〜100倍」のゾーンに明確なエッジを見出している。RGS 1.0 もまた、的中率（Accuracy）を追うのではなく、期待値の非対称性が大きいロングショット領域を恐れずに攻めるアルゴリズム設計が必要である。
4.2 伝説のAI「Mamba」のロジック解析
かつて回収率130%以上を維持し、ニコニコ動画等で話題となった「Mamba」のロジックは、実運用における重要な教訓を含んでいる 。
 * 全買い目評価: Mambaは単勝だけでなく、馬連、3連単などすべての券種の組み合わせについて確率を計算し、リアルタイムオッズと比較していた。
 * コンフィデンス・スレッショルド（閾値）: Mambaは、計算上の期待値（EV）が1.0を超えていれば即座に賭けるわけではなかった。AI自身の投票によるオッズ低下（マーケットインパクト）やモデルの誤差を見込み、「EV > 1.4」といった高いハードルを設定していた。締め切り直前にこの閾値を動的に調整することで、リスクをコントロールしていた。
 * 教訓: RGS 1.0 は、予測モデルだけでなく、「オッズ予測モデル（Slippage Model）」を実装し、自分の投票がオッズをどれだけ下げるかを予測した上で、それでも利益が出る場合にのみ投票する仕組みが必要である。
4.3 楽天AI（Rakuten AI）の戦略的推測
楽天の競馬AIに関する直接的な技術詳細は公開されていないが、楽天技術研究所（RIT）の研究論文からその戦略を逆算できる 。
 * レコメンデーション技術の応用: 楽天はEコマースで培った「協調フィルタリング」や「行列分解」技術を応用している可能性が高い。これは、ユーザーの購買行動（馬券購入履歴）から、「この馬を買う人はこの馬も買う」といった傾向を分析し、**大衆心理（マーケットセンチメント）**をモデル化するアプローチである。
 * 強み: 大衆が過剰反応している（過剰投票されている）馬を見抜く能力に長けていると推測される。
 * 弱点: 「馬そのもの」の物理的な状態よりも、「ユーザーデータ」に依存している可能性がある。ここが、生体力学的アプローチを採るRGS 1.0 が突き崩すべき隙である。
5. RGS 1.0 / HQS (AAS) の改善点と対楽天戦略
以上の分析に基づき、RGS 1.0 を業界最高水準へと引き上げるための具体的な改善戦略を提示する。
5.1 戦略的柱1：アルゴリズムとデータ構造の革新
 * ハイブリッド・アンサンブルの実装:
   * 単一のLightGBMモデルへの依存を脱却する。
   * TabTransformer：カテゴリ変数（血統、騎手ID）の埋め込み表現学習用。
   * Bi-LSTM / Transformer：過去のレース履歴（時系列データ）からのコンテキスト抽出用。
   * GBDT：上記の特徴量を統合し、最終的な決定を下す「メタ学習器」として使用 。
 * 損失関数の最適化:
   * 分類問題（Cross-Entropy）ではなく、**ランキング学習（Learning-to-Rank）**の損失関数（LambdaRank, RankNet）を採用する。これにより、3連単などの高配当券種に必要な「着順の序列」の予測精度を向上させる 。
5.2 戦略的柱2：特徴量エンジニアリングの深化
 * 「上がり3ハロン」と「コーナー通過順」の再定義:
   * 単なるタイムや順位ではなく、**「トラックバイアス補正済み相対速度」**へと昇華させる。例えば、「第3コーナーから第4コーナーにかけて、馬群の外側を回りながらどれだけ加速したか（遠心力によるロスを考慮した真の加速力）」を特徴量とする 。
 * ベイズ縮小によるスタッツ補正:
   * 騎手や種牡馬の勝率データに対し、前述の経験的ベイズ縮小を適用する。これにより、サンプル不足によるノイズを除去し、モデルが信頼性の低いデータに過学習するのを防ぐ 。
 * オッズの時系列特徴量:
   * 締め切り1時間前から5分前までのオッズ変動（オッズドロップ）を特徴量化する。これはインサイダー投票やスマートマネーの痕跡を捉えるための「対楽天」キラー機能となる。
5.3 戦略的柱3：実運用と資金管理
 * 動的閾値（Dynamic Thresholding）:
   * Mambaの戦略を踏襲し、レースまでの残り時間に応じて期待値の閾値を変動させる。
   *    * 締め切り直前ほどオッズが確定に近づくため、閾値を下げてエントリー回数を確保する。
 * ポートフォリオ・ケリー:
   * 単一レース内での賭け金配分だけでなく、同時刻に開催される他会場（例：中山と阪神）のレースも含めたポートフォリオ全体での0.25倍フラクショナル・ケリー運用を行う。これにより、全損リスクを極限まで低減させる 。
5.4 結論：「楽天AI超え」のシナリオ
楽天AIが「ビッグデータ（量）」と「大衆心理の把握」で市場を支配しようとするならば、RGS 1.0 は**「ディープデータ（質）」と「物理的真実の把握」**で対抗すべきである。
 * 差別化の源泉: 楽天が見ていない（あるいは見ることが難しい）映像解析データ、詳細なトラッキングデータ、そしてWHRのような高度な数理モデルによる「真の能力評価」である。
 * ターゲット市場: 楽天AIの影響力が強いJRAの主要レースだけでなく、データ整備が遅れており、かつドメイン適応によって優位性を発揮しやすい**NAR（地方競馬）**市場を積極的な収益源とする。
この「Deep Specialist（深層専門家）」戦略こそが、汎用的な巨人である楽天AIを局地戦で凌駕し、持続的なAlphaを獲得する唯一の道である。
References:

