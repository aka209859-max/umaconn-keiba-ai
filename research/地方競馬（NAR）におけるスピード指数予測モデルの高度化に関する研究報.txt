地方競馬（NAR）におけるスピード指数予測モデルの高度化に関する研究報告書：単走参照型から時系列アンサンブル学習へのパラダイムシフト1. 序論1.1 研究の背景とNAR-SIの定義地方競馬全国協会（NAR）が管轄する日本の地方競馬は、中央競馬（JRA）とは異なる独自の競技特性を有している。小回りコースが主体であること、ダート競走が中心であること、そして何よりも競走馬の出走頻度が極めて高いことが挙げられる。この環境下において、競走馬の能力を客観的に評価するための指標として「NAR-SI（Speed Index）」が開発された。NAR-SIは、レースの走破タイムを基準タイム（Standard Time）と比較し、馬場差（Track Variant）や斤量差を補正することで、異なる競馬場・距離・馬場状態で記録されたタイムを統一的な「能力値」として比較可能にすることを目的としている1。Andrew Beyerによって1970年代に提唱されたBeyer Speed Figure1や、日本における西田式スピード指数2と同様に、NAR-SIは以下の基本式によって定義される：$$NAR\text{-}SI = \text{BaseValue} - (\text{RaceTime} - \text{StandardTime}) \times \text{DistanceFactor} + \text{Corrections}$$この指数は、理論上、競走馬が発揮したパフォーマンスの絶対値を表すものであり、過去の指数履歴を用いることで将来のレース結果を予測することが可能となる。本プロジェクトにおける数値目標は、単勝的中率30-40%、複勝圏内率70-80%の達成である。1.2 現行モデル（Ver.2.1）の課題と限界現在運用されている「前走NAR-SI比較方式（Ver.2.1）」は、2024年の年間13,444レースの運用実績において、単勝的中率24.0%、複勝圏内率51.1%という結果に留まっている。これは目標値に対して単勝で約6-16ポイント、複勝で約20-30ポイントの不足を意味しており、統計的に有意な予測モデルとしては不十分な水準にあると言わざるを得ない。現行モデルの根本的な脆弱性は、その予測ロジックが「前走」という単一のデータポイントに過度に依存している点にある。Ver.2.1のアルゴリズムは、前走のNAR-SIに対し、今回の斤量増減や騎手変更による線形補正を加えるだけの決定論的（Deterministic）なアプローチを採用している。具体例として、以下のシナリオを想定する：馬A: 前走NAR-SI 105（水沢 1400m 良）+ 補正 -2 = 103馬C: 前走NAR-SI 110（川崎 1500m 稍重）+ 補正 -5 = 105この場合、モデルは単純に $105 > 103$ であるため「馬Cが先着する」と予測する。しかし、この比較は「前走のパフォーマンスが、その馬の真の能力を正確に代表しており、かつ次走でも再現される」という極めて強い、そして現実離れした仮定に基づいている。競馬は確率的な事象であり、展開のアヤ、位置取り、馬場のバイアス、馬の体調変動などにより、走破タイム（およびそこから算出されるSI）は大きな分散を持つ確率変数である3。単一のサンプリング結果である前走指数のみを絶対視することは、信号（Signal）とノイズ（Noise）を混同する危険性を孕んでいる。1.3 研究目的とVer.3.0の提案本研究は、現行の単走参照モデルの限界を打破するため、時系列データ解析と機械学習を導入した「過去3走からの予測指数方式（Ver.3.0）」の理論的・実証的優位性を検証することを目的とする。Ver.3.0では、過去3走以上の指数履歴をベクトルとして扱い、トレンド（上昇・下降）、安定性（ボラティリティ）、およびコンテキスト（条件適性）を統合的に学習することで、予測精度を飛躍的に向上させることを目指す。本報告書では、以下の5つのリサーチクエスチョン（RQ）に基づき、詳細な分析と実装指針を提示する。RQ1: 前走NAR-SI比較方式の理論的妥当性とその欠陥の解明RQ2: 過去3走データを用いたトレンド予測の理論的優位性RQ3: 地方競馬特有の高頻度出走データの特性活用RQ4: LightGBMを用いた非線形モデリングと特徴量設計RQ5: Python 3.14/PostgreSQL 17環境における実装とリスク管理2. RQ1: 前走NAR-SI比較方式の理論的妥当性と構造的欠陥2.1 点推定のリスクと「回帰への平均」の無視統計学的に、競走馬のパフォーマンス $P$ は、その馬固有の潜在能力 $\mu$ と、レースごとのランダムな誤差項 $\epsilon$ の和で表現できる。$$P_t = \mu + \epsilon_t, \quad \epsilon_t \sim N(0, \sigma^2)$$現行のVer.2.1は、前走の観測値 $P_{t-1}$ をそのまま次走の予測値 $\hat{P}_t$ として利用している（$\hat{P}_t \approx P_{t-1}$）。しかし、もし前走で $\epsilon_{t-1}$ が大きな正の値（＝展開が向いた、好スタートを切った等のラッキーな事象）を取った場合、観測された指数は真の能力 $\mu$ よりも過大評価される。統計的性質として、次走の誤差項 $\epsilon_t$ は期待値0に戻ろうとするため、パフォーマンスは低下する可能性が高い。これを「回帰への平均（Regression to the Mean）」と呼ぶ。Ver.2.1はこの現象を考慮せず、前走で好走した馬（高い $\epsilon_{t-1}$ を持つ馬）を過剰に評価し、逆に不利を受けて指数を落とした馬（負の $\epsilon_{t-1}$ を持つ馬）を過小評価する傾向がある。これが単勝的中率24%という低迷の主因であると考えられる。2.2 異種条件間の直接比較におけるバイアスRQ1で提示された「水沢1400m（小回り・平坦）」と「大井1600m（広大・直線長い）」の指数の直接比較は、コース適性（Track Aptitude）という隠れ変数を無視している点で理論的欠陥がある。NAR-SIは基準タイムによって競馬場間のレベル差を補正しているが、馬個体の適性は補正されていない。Beyerが指摘するように、特定のトラックバイアス（内枠有利、逃げ有利など）が存在する場合、そのバイアスに乗じて出した指数は、バイアスの異なる次走では再現されない5。現行システムにおける $\text{補正}$ 項は、斤量や騎手という明示的なパラメータのみを扱っており、コース形状や馬場状態の相性といった非線形な相互作用を捉えきれていない。2.3 「バウンス（Bounce）」現象の看過競馬予測、特にスピード指数理論において無視できないのが「バウンス（Bounce）」現象である。これは、馬が自己ベストを大幅に更新するような激走をした直後、肉体的・精神的な疲労により、次走でパフォーマンスを大きく落とす現象を指す7。現行方式では、「前走指数が高い＝強い」と判断するため、まさにこの「バウンスの危険性が最も高い馬」を「最も有力な馬」として推奨してしまう構造的欠陥がある。これは特に、能力の限界を使って走る下級条件や、疲労回復の遅い高齢馬において顕著な予測精度の低下を招く。3. RQ2: 過去3走からの予測指数方式（Ver.3.0）の理論的優位性3.1 時系列情報の平滑化と真の能力の推定提案するVer.3.0では、過去3走の指数ベクトル $S =$ を入力とする。これにより、以下の数理的アプローチが可能となる。単純移動平均（SMA）によるノイズ除去:3走の平均値 $\bar{S}$ を用いることで、単発のレースにおけるランダムノイズ $\epsilon$ の分散を縮小できる。中心極限定理の応用により、観測数が増えるほど標本平均は真の母平均（真の能力 $\mu$）に収束する。$$\text{Var}(\bar{S}) = \frac{\sigma^2}{n}$$$n=3$ とすることで、単一レース依存と比較して分散を1/3に低減する効果が期待でき、予測の安定性が向上する8。3.2 トレンド（傾き）の検出と状態推定過去3走のデータは、単なる平均値以上の情報量を持つ。指数の時系列推移（Trend）を分析することで、馬の現在のコンディションサイクル（Form Cycle）を推定できる10。上昇トレンド（Ascending）: $SI_{t-3} < SI_{t-2} < SI_{t-1}$解釈: 若駒の成長期、あるいは休養明けからの叩き良化型。次走でさらなる指数上昇（$\hat{P}_t > P_{t-1}$）が見込める。下降トレンド（Descending）: $SI_{t-3} > SI_{t-2} > SI_{t-1}$解釈: 疲労の蓄積、ピークアウト、あるいは故障の前兆。次走は指数を落とすリスクが高い。V字回復 / 山型推移:これらのパターン認識は、前走データのみでは不可能であり、3走データを用いる最大の利点である。機械学習モデルは、これらの形状パターンと次走結果の相関を学習することができる。3.3 重み付け平均と減衰（Decay）モデル過去のデータは全て等価値ではない。直近のレースほど現在の能力を強く反映していると考えるのが自然である。Ver.3.0では、時間経過に応じた減衰係数 $\lambda$ を導入した加重平均（Weighted Average）を採用すべきである8。$$\text{WeightedSI} = \frac{\sum_{i=1}^{3} w_i \cdot SI_{t-i}}{\sum w_i}, \quad w_i = e^{-\lambda \cdot \text{DaysSince}_{t-i}}$$または、単純に $w_1=0.5, w_2=0.3, w_3=0.2$ のような固定重みを用いることで、トレンドへの感応度とノイズ耐性のバランスを調整可能となる。これは金融時系列分析におけるEMA（指数平滑移動平均）の応用であり、競馬予測においても有効性が示されている11。4. RQ3: 地方競馬（NAR）における指数予測の特殊性4.1 高頻度出走と短いサイクルの活用中央競馬（JRA）では月1回程度の出走が標準的だが、地方競馬では中1週〜中2週、場合によっては連闘という過密スケジュールが常態化している。この「高頻度データ（High-Frequency Data）」は、時系列予測において大きなアドバンテージとなる12。データポイント間の時間間隔が短いため、馬の調子変動（Volatility）をより精緻に捉えることができる。例えば、「中1週で指数を上げるタイプ」や「間隔が詰まると指数を下げるタイプ」といった個体ごとの疲労耐性特性を、過去3走の履歴から学習させることが容易である。4.2 コース・距離の限定性とスペシャリストの存在地方競馬は、特定の競馬場（例：大井のみ、園田のみ）に所属し、同じコースを繰り返し走る馬が多い。これにより、特定の「コース適性」が指数に強く反映される。Ver.3.0では、過去3走の中に「今回と同じ競馬場・距離」が含まれているかどうかを特徴量（Categorical Feature interaction）として組み込むことで、「得意条件での巻き返し」を予測できる。前走が異なる条件で指数を落としていても、2走前・3走前が得意条件で好指数であれば、モデルはそこを評価点としてピックアップできる。4.3 馬場状態（Track Condition）の激しい変動地方競馬のダートコースは、天候による砂の含水率の変化で時計が劇的に変わる（良馬場と不良馬場では2秒以上の差が出ることも稀ではない）。NAR-SIはこれを基準タイムで補正するが、馬によって「重馬場は得意だが良馬場は苦手」という適性の偏り（Bias）が存在する5。過去3走のデータに、それぞれのレース時点での馬場状態変数を付与することで、モデルは「重馬場の時だけ指数が跳ね上がる」といったパターン（Interaction Effect）を認識可能となる。5. RQ4: 機械学習モデルの設計指針（Feature Engineering & Modeling）単なるルールベースの平均計算ではなく、勾配ブースティング決定木（GBDT）を用いた機械学習モデルへの移行を提案する。ここでは、具体的にLightGBMを用いたモデル設計を詳述する。5.1 モデル選択：なぜLightGBMなのかLightGBMは、以下の理由から本プロジェクトに最適なアルゴリズムである13。欠損値の自動処理: 地方競馬では、キャリア3戦未満の若駒や、転入馬などで過去データが欠損しているケースが多発する。LightGBMは欠損値を情報として学習（分岐方向を最適化）できるため、インプテーション（穴埋め）によるノイズ混入を回避できる。カテゴリ変数の効率的処理: 騎手ID、調教師ID、競馬場コードなどの高カーディナリティなカテゴリ変数を、One-hot Encodingなしで効率的に処理できる。非線形相互作用の学習: 「馬体重500kg以上」×「短距離」×「重馬場」＝「好走確率大」といった、変数間の複雑な非線形関係を決定木の深さによって捉えることができる。高速な学習速度: 13,444レース（出走馬延べ約15万頭分）のデータ量であれば、数分〜数十分で学習が完了し、1週間の開発期間内で十分なハイパーパラメータ探索が可能である。5.2 特徴量エンジニアリング（Feature Engineering）の詳細モデルの精度は特徴量の質に依存する11。Ver.3.0では以下の特徴量群を生成する。A. 時系列NAR-SI特徴量 (Past Performance Metrics)narsi_lag_1, narsi_lag_2, narsi_lag_3: 過去1-3走前のNAR-SI生データ。narsi_mean_3: 過去3走の平均値。ベース能力の推定。narsi_std_3: 過去3走の標準偏差。パフォーマンスの安定性（ボラティリティ）。narsi_slope: 直近3走の回帰直線の傾き。調子の上昇/下降トレンド。narsi_max_3: 過去3走の最大値。ポテンシャルの上限（Ceiling）。narsi_weighted: 直近を重視した加重平均（重み：0.5, 0.3, 0.2など）。B. コンテキスト差分特徴量 (Contextual Differentials)今回のレース条件と過去の条件との乖離を数値化する。diff_dist_1: 今回距離 - 前走距離。距離延長（+）か短縮（-）か。diff_weight_1: 今回斤量 - 前走斤量。days_since_last: 前走からの経過日数。間隔の影響。same_jockey_flag: 前走と同じ騎手か否か。same_course_flag: 今回の競馬場・コースが過去3走以内に含まれるか。C. 相対評価特徴量 (Relative Metrics)レース内での相対的な位置付けを示す17。rank_in_race_narsi_mean: 出走メンバー内での narsi_mean_3 の順位。z_score_narsi: 出走メンバーの平均SIに対する、当該馬の偏差値。D. 展開・ペース予測特徴量 (Pace Logic)position_avg_3: 過去3走の4コーナー通過順位の平均。先行力（Early Speed）の指標2。late_speed_3: （上がり3ハロンタイムの偏差値）の平均。末脚の鋭さ。5.3 目的変数（Target Variable）の設計と過学習対策目的変数の設定:単に「次走のNAR-SI（回帰）」を予測するだけでなく、実用性を考慮し「レース内順位（Ranking）」または「複勝圏内確率（Classification）」をターゲットとすることを推奨する。アプローチ1（回帰）: Target = Next_NAR_SI。二乗誤差（RMSE）を最小化する。アプローチ2（ランク学習）: LightGBMの objective='lambdarank' を使用し、レース内での相対順位を学習させる。これにより、レース全体のタイムレベル（馬場差など）の影響を受けにくくなる。過学習（Overfitting）対策:early_stopping: 検証データの誤差が改善しなくなったら学習を打ち切る。feature_fraction: 木を作成するたびに特徴量をランダムにサンプリング（例: 70%）し、特定の特徴量への依存を防ぐ。min_data_in_leaf: 葉ノードに含まれる最小データ数を制限（例: 20-50）し、外れ値への過剰適合を防ぐ。6. RQ5: 実装上の注意点とリスク管理6.1 データリーケージ（Data Leakage）の厳格な防止競馬予測モデル構築において最も致命的なミスは、未来の情報を学習時に使ってしまう「リーケージ」である19。禁止事項:レース当日の馬体重（レース直前まで不明なため、モデル運用時には使えない場合がある。前走馬体重を使うか、予測値を使う）。確定オッズ（締め切り後のオッズを使ってはいけない）。その日の「馬場差」補正値（全レース終了後に確定するため、予測時点では未知）。対策:特徴量は全て「レース発走前」に入手可能なデータのみで構成する。オッズを使用する場合は「前日最終オッズ」や「朝一オッズ」に限定する。6.2 時系列バリデーション（Walk-Forward Validation）ランダムにデータを分割するK-Fold交差検証は、時系列データでは「未来のデータで過去を予測する」ことになり、精度を不当に高く見積もってしまうため使用してはならない21。必ず**Walk-Forward Validation（前方検証）**を採用する。Step 1: 2022年1月〜2023年6月で学習 $\rightarrow$ 2023年7月をテスト。Step 2: 2022年1月〜2023年7月で学習 $\rightarrow$ 2023年8月をテスト。...Step N: 2022年1月〜2023年12月で学習 $\rightarrow$ 2024年1月をテスト。このようにウィンドウをスライドさせながら検証することで、実際の運用環境（未来のレースを予測し続ける）を正確にシミュレーションできる。6.3 データ不足（Cold Start）への対処新馬や転入馬など、過去3走のデータが揃っていない馬（Cold Start問題）への対処が必要である。LightGBMの活用: 前述の通り、欠損値をそのまま入力する。補完戦略:血統データ（種牡馬の平均SI）や、調教師・騎手の勝率データで補完する。「初出走フラグ」を立て、モデルにその不確実性を学習させる。6.4 Python 3.14 & PostgreSQL 17 実装アーキテクチャ制約条件にある環境下での効率的な実装構成案を以下に示す。コンポーネント技術スタック役割・処理内容データ基盤PostgreSQL 1713,444レースの生データ格納。Window関数（AVG() OVER (PARTITION BY horse_id ORDER BY date ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING)）を用いて、SQL側で効率的にラグ特徴量や移動平均を計算する9。前処理・学習Python 3.14pandasによるデータフレーム操作、optunaによるハイパーパラメータ探索、lightgbmによるモデル学習。Python 3.14のJITコンパイラ機能を活用し、大規模データの処理速度を向上させる。実験管理MLflow実験ごとのパラメータ、特徴量セット、検証スコア（RMSE, Precision@1）を記録し、ベストモデルを選定する。7. 期待される研究成果と結論7.1 理論的妥当性の確立本研究により、Ver.3.0（過去3走方式）は、Ver.2.1（前走方式）が抱える「点推定の脆弱性」「バウンスの看過」「コンテキスト無視」といった理論的欠陥を克服するモデルであることが示される。時系列情報の統合は、競馬予測における「不確実性の縮小」に数学的に寄与する。7.2 期待される精度向上機械学習を用いた他競技や類似ドメインの先行事例11に基づけば、以下の改善が見込まれる。単勝的中率: 24.0% $\rightarrow$ 28.0% 〜 32.0% （+4〜8ポイント）複勝圏内率: 51.1% $\rightarrow$ 60.0% 〜 65.0% （+9〜14ポイント）特に、人気薄の好走馬（穴馬）の検知能力において、トレンド特徴量が威力を発揮し、回収率（ROI）の大幅な改善が期待できる。7.3 実装の具体的指針とロードマップ1週間の開発期間における推奨ロードマップは以下の通りである。Day 1-2 (SQL): PostgreSQL上でWindow関数を駆使し、過去3走のSI、トレンド、間隔などの「基本特徴量テーブル」を作成する。Day 3 (Python): LightGBMのベースラインモデルを構築し、Walk-Forward Validationで評価環境を整備する。Day 4-5 (Feature Ops): 特徴量の追加と選定（Feature Selection）。特に「コース適性」や「騎手×競馬場」の交互作用特徴量を重点的にテストする。Day 6 (Tuning): Optunaを用いたハイパーパラメータチューニング。Day 7 (Reporting): 最終精度の検証と、実運用に向けた推論パイプラインのコード整理。7.4 リスクと落とし穴過学習リスク: 過去のデータに適合しすぎて、未知のデータ（将来のレース）で勝てなくなるリスク。これには厳格なWalk-Forward Validationと、特徴量数の抑制（重要なものに絞る）で対抗する。環境変化（Concept Drift）: 競馬場の改修やルールの変更により、過去の傾向が通用しなくなるリスク。直近1年のデータに重みを置く学習データのサンプリング戦略で緩和する。本報告書で提示したVer.3.0への移行は、地方競馬予測におけるデータサイエンスの適用レベルを一段階引き上げ、目標とする高い的中率と収益性の実現に向けた確固たる基盤となるものである。