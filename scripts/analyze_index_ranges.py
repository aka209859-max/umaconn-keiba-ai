#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
4æŒ‡æ•°ã®å‡ºåŠ›ç¯„å›²åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
- ãƒ†ãƒ³æŒ‡æ•°ã€ä½ç½®æŒ‡æ•°ã€ä¸ŠãŒã‚ŠæŒ‡æ•°ã€ãƒšãƒ¼ã‚¹æŒ‡æ•°ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹ä¸Šé™ãƒ»ä¸‹é™ã‚’ç¢ºèª
- ç«¶é¦¬å ´åˆ¥ã€è·é›¢åˆ¥ã€ã‚¯ãƒ©ã‚¹åˆ¥ã®å‡ºåŠ›ç¯„å›²ã‚’å¯è¦–åŒ–
- ãƒ“ãƒ³ä»˜ã‘ï¼ˆå¾—ç‚¹åŒ–ï¼‰ã®ãŸã‚ã®æœ€é©ãªåŒºé–“ã‚’æ±ºå®š

å®Ÿè¡Œä¾‹:
    python scripts/analyze_index_ranges.py --db umatabi.db --output reports/index_ranges.csv
"""

import sys
import os
import sqlite3
import pandas as pd
import numpy as np
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.index_calculator import calculate_all_indexes

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆå…¨14å ´ï¼‰
KEIBAJO_CODES = [30, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 50, 54, 55]

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è·é›¢å¸¯
KYORI_RANGES = [1000, 1200, 1400, 1600, 1800, 2000, 2100, 2400]

# ã‚¯ãƒ©ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆä»®å®šï¼‰
GRADE_CODES = ['A', 'B', 'C', 'D', 'E', 'ä¸€èˆ¬']

def load_race_data(db_path: str, limit: int = None) -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        limit: èª­ã¿è¾¼ã‚€ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®ä¸Šé™ï¼ˆNone=å…¨ä»¶ï¼‰
    
    Returns:
        pd.DataFrame: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
    """
    conn = sqlite3.connect(db_path)
    
    limit_clause = f"LIMIT {limit}" if limit else ""
    
    query = f"""
    SELECT 
        keibajo_code,
        kyori,
        grade_code,
        zenhan_3f,
        kohan_3f,
        soha_time,
        corner_1,
        corner_2,
        corner_3,
        corner_4,
        babajotai_code_dirt,
        furi_code,
        wakuban,
        kinryo,
        bataiju,
        tosu,
        kakutei_chakujun,
        tansho_odds
    FROM races
    WHERE zenhan_3f > 0 AND kohan_3f > 0 AND soha_time > 0
    {limit_clause}
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}ãƒ¬ãƒ¼ã‚¹")
    return df

def calculate_indexes_for_all(df: pd.DataFrame) -> pd.DataFrame:
    """
    å…¨ãƒ¬ãƒ¼ã‚¹ã®4æŒ‡æ•°ã‚’è¨ˆç®—
    
    Args:
        df: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        pd.DataFrame: 4æŒ‡æ•°ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    results = []
    
    for idx, row in df.iterrows():
        if (idx + 1) % 1000 == 0:
            print(f"  å‡¦ç†ä¸­... {idx + 1:,} / {len(df):,} ({(idx+1)/len(df)*100:.1f}%)")
        
        try:
            horse_data = {
                'zenhan_3f': row['zenhan_3f'],
                'kohan_3f': row['kohan_3f'],
                'soha_time': row['soha_time'],
                'corner_1': row['corner_1'],
                'corner_2': row['corner_2'],
                'corner_3': row['corner_3'],
                'corner_4': row['corner_4'],
                'kyori': row['kyori'],
                'babajotai_code_dirt': row['babajotai_code_dirt'],
                'keibajo_code': row['keibajo_code'],
                'furi_code': row.get('furi_code', '00'),
                'wakuban': row.get('wakuban', 0),
                'tosu': row.get('tosu', 12),
                'kinryo': row.get('kinryo', 54.0),
                'bataiju': row.get('bataiju', 460.0)
            }
            
            race_info = {
                'grade_code': row.get('grade_code', 'E')
            }
            
            result = calculate_all_indexes(horse_data, race_info)
            
            results.append({
                'keibajo_code': row['keibajo_code'],
                'kyori': row['kyori'],
                'grade_code': row.get('grade_code', 'E'),
                'ten_index': result['ten_index'],
                'position_index': result['position_index'],
                'agari_index': result['agari_index'],
                'pace_index': result['pace_index'],
                'pace_type': result.get('pace_type', 'M'),
                'kakutei_chakujun': row.get('kakutei_chakujun', 99),
                'tansho_odds': row.get('tansho_odds', 0.0)
            })
        except Exception as e:
            print(f"  âš ï¸ è¡Œ{idx}ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return pd.DataFrame(results)

def analyze_ranges(df: pd.DataFrame) -> pd.DataFrame:
    """
    æŒ‡æ•°ã®ç¯„å›²ã‚’åˆ†æ
    
    Args:
        df: 4æŒ‡æ•°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    
    Returns:
        pd.DataFrame: çµ±è¨ˆã‚µãƒãƒªãƒ¼
    """
    # å…¨ä½“çµ±è¨ˆ
    overall_stats = {
        'segment': 'å…¨ä½“',
        'keibajo_code': 'ALL',
        'kyori': 'ALL',
        'grade_code': 'ALL',
        'count': len(df),
        'ten_min': df['ten_index'].min(),
        'ten_max': df['ten_index'].max(),
        'ten_mean': df['ten_index'].mean(),
        'ten_std': df['ten_index'].std(),
        'pos_min': df['position_index'].min(),
        'pos_max': df['position_index'].max(),
        'pos_mean': df['position_index'].mean(),
        'pos_std': df['position_index'].std(),
        'agari_min': df['agari_index'].min(),
        'agari_max': df['agari_index'].max(),
        'agari_mean': df['agari_index'].mean(),
        'agari_std': df['agari_index'].std(),
        'pace_min': df['pace_index'].min(),
        'pace_max': df['pace_index'].max(),
        'pace_mean': df['pace_index'].mean(),
        'pace_std': df['pace_index'].std()
    }
    
    stats_list = [overall_stats]
    
    # ç«¶é¦¬å ´åˆ¥çµ±è¨ˆ
    for keibajo in df['keibajo_code'].unique():
        subset = df[df['keibajo_code'] == keibajo]
        stats_list.append({
            'segment': 'ç«¶é¦¬å ´åˆ¥',
            'keibajo_code': keibajo,
            'kyori': 'ALL',
            'grade_code': 'ALL',
            'count': len(subset),
            'ten_min': subset['ten_index'].min(),
            'ten_max': subset['ten_index'].max(),
            'ten_mean': subset['ten_index'].mean(),
            'ten_std': subset['ten_index'].std(),
            'pos_min': subset['position_index'].min(),
            'pos_max': subset['position_index'].max(),
            'pos_mean': subset['position_index'].mean(),
            'pos_std': subset['position_index'].std(),
            'agari_min': subset['agari_index'].min(),
            'agari_max': subset['agari_index'].max(),
            'agari_mean': subset['agari_index'].mean(),
            'agari_std': subset['agari_index'].std(),
            'pace_min': subset['pace_index'].min(),
            'pace_max': subset['pace_index'].max(),
            'pace_mean': subset['pace_index'].mean(),
            'pace_std': subset['pace_index'].std()
        })
    
    # è·é›¢åˆ¥çµ±è¨ˆ
    for kyori in df['kyori'].unique():
        subset = df[df['kyori'] == kyori]
        if len(subset) < 50:  # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
        stats_list.append({
            'segment': 'è·é›¢åˆ¥',
            'keibajo_code': 'ALL',
            'kyori': kyori,
            'grade_code': 'ALL',
            'count': len(subset),
            'ten_min': subset['ten_index'].min(),
            'ten_max': subset['ten_index'].max(),
            'ten_mean': subset['ten_index'].mean(),
            'ten_std': subset['ten_index'].std(),
            'pos_min': subset['position_index'].min(),
            'pos_max': subset['position_index'].max(),
            'pos_mean': subset['position_index'].mean(),
            'pos_std': subset['position_index'].std(),
            'agari_min': subset['agari_index'].min(),
            'agari_max': subset['agari_index'].max(),
            'agari_mean': subset['agari_index'].mean(),
            'agari_std': subset['agari_index'].std(),
            'pace_min': subset['pace_index'].min(),
            'pace_max': subset['pace_index'].max(),
            'pace_mean': subset['pace_index'].mean(),
            'pace_std': subset['pace_index'].std()
        })
    
    return pd.DataFrame(stats_list)

def suggest_bins(df: pd.DataFrame) -> dict:
    """
    ãƒ“ãƒ³ä»˜ã‘ã®ææ¡ˆ
    
    Args:
        df: 4æŒ‡æ•°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    
    Returns:
        dict: å„æŒ‡æ•°ã®ãƒ“ãƒ³åŒºé–“ææ¡ˆ
    """
    suggestions = {}
    
    for index_name in ['ten_index', 'position_index', 'agari_index', 'pace_index']:
        data = df[index_name].dropna()
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«æ³•ï¼ˆ10åˆ†ä½ï¼‰
        percentiles = np.percentile(data, [10, 20, 30, 40, 50, 60, 70, 80, 90])
        
        # ç­‰é–“éš”æ³•
        min_val = data.min()
        max_val = data.max()
        equal_bins = np.linspace(min_val, max_val, 11)
        
        suggestions[index_name] = {
            'min': float(min_val),
            'max': float(max_val),
            'mean': float(data.mean()),
            'std': float(data.std()),
            'percentile_bins': percentiles.tolist(),
            'equal_bins': equal_bins.tolist()
        }
    
    return suggestions

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='4æŒ‡æ•°ã®å‡ºåŠ›ç¯„å›²ã‚’åˆ†æ')
    parser.add_argument('--db', type=str, default='umatabi.db', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', type=str, default='reports/index_ranges.csv', help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--limit', type=int, default=None, help='å‡¦ç†ã™ã‚‹ãƒ¬ãƒ¼ã‚¹æ•°ã®ä¸Šé™')
    
    args = parser.parse_args()
    
    print("="*60)
    print("4æŒ‡æ•°ã®å‡ºåŠ›ç¯„å›²åˆ†æ")
    print("="*60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\n[1/4] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    df_raw = load_race_data(args.db, limit=args.limit)
    
    # 4æŒ‡æ•°è¨ˆç®—
    print("\n[2/4] 4æŒ‡æ•°ã‚’è¨ˆç®—ä¸­...")
    df_indexes = calculate_indexes_for_all(df_raw)
    
    # ç¯„å›²åˆ†æ
    print("\n[3/4] ç¯„å›²åˆ†æä¸­...")
    df_stats = analyze_ranges(df_indexes)
    
    # ãƒ“ãƒ³ææ¡ˆ
    print("\n[4/4] ãƒ“ãƒ³ä»˜ã‘ææ¡ˆã‚’ç”Ÿæˆä¸­...")
    bin_suggestions = suggest_bins(df_indexes)
    
    # çµæœä¿å­˜
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df_stats.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    # ãƒ“ãƒ³ææ¡ˆã‚’JSONå‡ºåŠ›
    import json
    bin_output_path = output_path.with_suffix('.json')
    with open(bin_output_path, 'w', encoding='utf-8') as f:
        json.dump(bin_suggestions, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… åˆ†æå®Œäº†ï¼")
    print(f"  - çµ±è¨ˆã‚µãƒãƒªãƒ¼: {output_path}")
    print(f"  - ãƒ“ãƒ³ææ¡ˆ: {bin_output_path}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ã€å…¨ä½“çµ±è¨ˆã‚µãƒãƒªãƒ¼ã€‘")
    print("="*60)
    overall = df_stats[df_stats['segment'] == 'å…¨ä½“'].iloc[0]
    print(f"\nãƒ¬ãƒ¼ã‚¹æ•°: {overall['count']:,}ä»¶\n")
    
    print(f"ãƒ†ãƒ³æŒ‡æ•°:")
    print(f"  ç¯„å›²: {overall['ten_min']:.1f} ~ {overall['ten_max']:.1f}")
    print(f"  å¹³å‡: {overall['ten_mean']:.1f} Â± {overall['ten_std']:.1f}")
    
    print(f"\nä½ç½®æŒ‡æ•°:")
    print(f"  ç¯„å›²: {overall['pos_min']:.1f} ~ {overall['pos_max']:.1f}")
    print(f"  å¹³å‡: {overall['pos_mean']:.1f} Â± {overall['pos_std']:.1f}")
    
    print(f"\nä¸ŠãŒã‚ŠæŒ‡æ•°:")
    print(f"  ç¯„å›²: {overall['agari_min']:.1f} ~ {overall['agari_max']:.1f}")
    print(f"  å¹³å‡: {overall['agari_mean']:.1f} Â± {overall['agari_std']:.1f}")
    
    print(f"\nãƒšãƒ¼ã‚¹æŒ‡æ•°:")
    print(f"  ç¯„å›²: {overall['pace_min']:.1f} ~ {overall['pace_max']:.1f}")
    print(f"  å¹³å‡: {overall['pace_mean']:.1f} Â± {overall['pace_std']:.1f}")
    
    print("\n" + "="*60)
    print("Play to Win! ğŸš€")
    print("="*60)

if __name__ == '__main__':
    main()
