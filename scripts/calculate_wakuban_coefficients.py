#!/usr/bin/env python3
"""
ä½ç½®æŒ‡æ•°ã®æ é †ä¿‚æ•°ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç®—å‡º

ç›®çš„:
- å…¨ç«¶é¦¬å ´Ã—è·é›¢Ã—æ ç•ªåˆ¥ã®å˜å‹/è¤‡å‹çš„ä¸­ç‡ã‹ã‚‰æ é †ä¿‚æ•°ã‚’ç®—å‡º
- ç¾è¡Œã®å›ºå®šä¿‚æ•°ï¼ˆwaku_correction * 15ï¼‰ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿‚æ•°ã«ç½®ãæ›ãˆã‚‹

å…¥åŠ›:
- data-1768033229370.csvï¼ˆå…¨ç«¶é¦¬å ´Ã—è·é›¢Ã—æ ç•ªåˆ¥ã®çš„ä¸­ç‡ï¼‰

å‡ºåŠ›:
- wakuban_coefficients.csvï¼ˆç«¶é¦¬å ´Ã—è·é›¢Ã—æ ç•ªåˆ¥ã®ä¿‚æ•°ï¼‰
- wakuban_coefficients.jsonï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ä½¿ç”¨ã™ã‚‹å½¢å¼ï¼‰

è¨ˆç®—å¼:
- å¹³å‡çš„ä¸­ç‡ = (å˜å‹çš„ä¸­ç‡ + è¤‡å‹çš„ä¸­ç‡) / 2
- åŸºæº–å€¤ = å„ç«¶é¦¬å ´Ã—è·é›¢ã®å…¨æ å¹³å‡çš„ä¸­ç‡
- æ é †ä¿‚æ•° = (å¹³å‡çš„ä¸­ç‡ - åŸºæº–å€¤) Ã— ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°

Author: NAR-AI-YOSO Project
Date: 2026-01-10
"""

import pandas as pd
import json
from pathlib import Path
from collections import defaultdict

# ============================
# è¨­å®š
# ============================

INPUT_CSV = '/home/user/uploaded_files/data-1768033229370.csv'
OUTPUT_CSV = '/home/user/webapp/nar-ai-yoso/data/wakuban_coefficients.csv'
OUTPUT_JSON = '/home/user/webapp/nar-ai-yoso/data/wakuban_coefficients.json'

# ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ï¼ˆä½ç½®æŒ‡æ•°ã¸ã®å½±éŸ¿åº¦ï¼‰
# ç¾è¡Œ: waku_correction * 15
# æ–°æ–¹å¼: (çš„ä¸­ç‡å·® - åŸºæº–å€¤) Ã— SCALE_FACTOR
SCALE_FACTOR = 1.5  # 1%ã®çš„ä¸­ç‡å·® = 1.5ç‚¹ã®æŒ‡æ•°å·®

# ============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================

print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
df = pd.read_csv(INPUT_CSV)

print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} è¡Œ")
print(f"   ç«¶é¦¬å ´æ•°: {df['keibajo_code'].nunique()}")
print(f"   è·é›¢æ•°: {df['distance'].nunique()}")
print(f"   æ ç•ªæ•°: {df['waku'].nunique()}")

# ============================
# å¹³å‡çš„ä¸­ç‡ã®è¨ˆç®—
# ============================

print("\nğŸ“Š å¹³å‡çš„ä¸­ç‡ã‚’è¨ˆç®—ä¸­...")

# å˜å‹ã¨è¤‡å‹ã®å¹³å‡çš„ä¸­ç‡
df['avg_hit_rate'] = (df['tansho_hit_rate'] + df['fukusho_hit_rate']) / 2

print(f"âœ… å¹³å‡çš„ä¸­ç‡ã®è¨ˆç®—å®Œäº†")
print(f"   æœ€å°: {df['avg_hit_rate'].min():.2f}%")
print(f"   æœ€å¤§: {df['avg_hit_rate'].max():.2f}%")
print(f"   å¹³å‡: {df['avg_hit_rate'].mean():.2f}%")

# ============================
# ç«¶é¦¬å ´Ã—è·é›¢åˆ¥ã®åŸºæº–å€¤ã‚’è¨ˆç®—
# ============================

print("\nğŸ¯ åŸºæº–å€¤ï¼ˆå„ç«¶é¦¬å ´Ã—è·é›¢ã®å…¨æ å¹³å‡ï¼‰ã‚’è¨ˆç®—ä¸­...")

baseline = df.groupby(['keibajo_code', 'distance'])['avg_hit_rate'].mean().reset_index()
baseline.columns = ['keibajo_code', 'distance', 'baseline_rate']

print(f"âœ… åŸºæº–å€¤ã®è¨ˆç®—å®Œäº†: {len(baseline)} çµ„ã¿åˆã‚ã›")

# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
df = df.merge(baseline, on=['keibajo_code', 'distance'], how='left')

# ============================
# æ é †ä¿‚æ•°ã®è¨ˆç®—
# ============================

print("\nğŸ”§ æ é †ä¿‚æ•°ã‚’è¨ˆç®—ä¸­...")

# ä¿‚æ•° = (å¹³å‡çš„ä¸­ç‡ - åŸºæº–å€¤) Ã— ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°
df['wakuban_coefficient'] = (df['avg_hit_rate'] - df['baseline_rate']) * SCALE_FACTOR

print(f"âœ… æ é †ä¿‚æ•°ã®è¨ˆç®—å®Œäº†")
print(f"   æœ€å°: {df['wakuban_coefficient'].min():.2f}")
print(f"   æœ€å¤§: {df['wakuban_coefficient'].max():.2f}")
print(f"   å¹³å‡: {df['wakuban_coefficient'].mean():.2f}")

# ============================
# CSVå‡ºåŠ›
# ============================

print(f"\nğŸ’¾ CSVå‡ºåŠ›ä¸­: {OUTPUT_CSV}")

output_df = df[[
    'keibajo_code', 'keibajo_name', 'distance', 'waku',
    'sample_count', 'tansho_hit_rate', 'fukusho_hit_rate',
    'avg_hit_rate', 'baseline_rate', 'wakuban_coefficient'
]].copy()

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
Path(OUTPUT_CSV).parent.mkdir(parents=True, exist_ok=True)

output_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
print(f"âœ… CSVå‡ºåŠ›å®Œäº†: {len(output_df)} è¡Œ")

# ============================
# JSONå‡ºåŠ›ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”¨ï¼‰
# ============================

print(f"\nğŸ’¾ JSONå‡ºåŠ›ä¸­: {OUTPUT_JSON}")

# æ§‹é€ : {keibajo_code: {kyori: {wakuban: coefficient}}}
coefficients = defaultdict(lambda: defaultdict(dict))

for _, row in df.iterrows():
    keibajo = str(int(row['keibajo_code']))
    kyori = int(row['distance'])
    waku = int(row['waku'])
    coef = round(float(row['wakuban_coefficient']), 2)
    
    coefficients[keibajo][kyori][waku] = coef

# JSONæ›¸ãè¾¼ã¿
with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
    json.dump(coefficients, f, ensure_ascii=False, indent=2)

print(f"âœ… JSONå‡ºåŠ›å®Œäº†")

# ============================
# çµ±è¨ˆã‚µãƒãƒªãƒ¼
# ============================

print("\n" + "="*60)
print("ğŸ“Š æ é †ä¿‚æ•°ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ï¼ˆç«¶é¦¬å ´åˆ¥ï¼‰")
print("="*60)

summary = df.groupby('keibajo_name').agg({
    'wakuban_coefficient': ['min', 'max', 'mean', 'std']
}).round(2)

print(summary)

print("\n" + "="*60)
print("ğŸ“Š æ é †ä¿‚æ•°ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ï¼ˆè·é›¢åˆ¥ï¼‰")
print("="*60)

summary_distance = df.groupby('distance').agg({
    'wakuban_coefficient': ['min', 'max', 'mean', 'std']
}).round(2)

print(summary_distance)

print("\n" + "="*60)
print("ğŸ¯ ç‰¹å¾´çš„ãªæ ç•ªä¿‚æ•°ï¼ˆãƒˆãƒƒãƒ—10ï¼‰")
print("="*60)

top10 = output_df.nlargest(10, 'wakuban_coefficient')[
    ['keibajo_name', 'distance', 'waku', 'wakuban_coefficient', 'avg_hit_rate']
]
print(top10.to_string(index=False))

print("\n" + "="*60)
print("âš ï¸ æ³¨æ„ãŒå¿…è¦ãªæ ç•ªä¿‚æ•°ï¼ˆãƒ¯ãƒ¼ã‚¹ãƒˆ10ï¼‰")
print("="*60)

worst10 = output_df.nsmallest(10, 'wakuban_coefficient')[
    ['keibajo_name', 'distance', 'waku', 'wakuban_coefficient', 'avg_hit_rate']
]
print(worst10.to_string(index=False))

print("\n" + "="*60)
print("âœ… å®Œäº†ï¼")
print("="*60)
print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
print(f"   - {OUTPUT_CSV}")
print(f"   - {OUTPUT_JSON}")
print("="*60)
