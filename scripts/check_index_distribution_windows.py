#!/usr/bin/env python3
"""
HQS 4æŒ‡æ•°ã®åˆ†å¸ƒç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆWindowsç”¨ï¼‰

ã€ç›®çš„ã€‘
å„æŒ‡æ•°ã®å€¤ãŒ10åŒºåˆ‡ã‚Šãƒ»5åŒºåˆ‡ã‚Šã§ã©ã®ã‚ˆã†ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹

ã€ä½¿ç”¨æ–¹æ³•ã€‘
python check_index_distribution_windows.py

ã€å‡ºåŠ›ã€‘
- å„æŒ‡æ•°ã®10åŒºåˆ‡ã‚Šåˆ†å¸ƒï¼ˆ-100ï½-90ã€-90ï½-80ã€...ã€90ï½100ï¼‰
- å„æŒ‡æ•°ã®5åŒºåˆ‡ã‚Šåˆ†å¸ƒï¼ˆ-100ï½-95ã€-95ï½-90ã€...ã€95ï½100ï¼‰
- CSV/JSONå½¢å¼ã§ä¿å­˜
"""

import os
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# ============================
# è¨­å®š
# ============================

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
DEFAULT_DATA_PATH = r'E:\UmaData\nar-analytics-python-v2\data-1768047611955.csv'
DEFAULT_START_DATE = '20231013'
DEFAULT_END_DATE = '20251231'
DEFAULT_SAMPLE_RATE = 0.1

# ============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================

def load_and_filter_data(file_path: str, start_date: str, end_date: str, sample_rate: float = 0.1):
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {file_path}")
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°èª­ã¿è¾¼ã¿
    df = pd.read_csv(file_path, skiprows=lambda i: i > 0 and np.random.rand() > sample_rate)
    print(f"   èª­ã¿è¾¼ã¿: {len(df):,}è¡Œï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°{int(sample_rate*100)}%ï¼‰")
    
    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿
    df['race_date'] = df['race_date'].astype(str)
    df = df[(df['race_date'] >= start_date) & (df['race_date'] <= end_date)]
    print(f"   æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿: {len(df):,}è¡Œï¼ˆ{start_date}ï½{end_date}ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    df = df.dropna(subset=['race_date', 'keibajo_code', 'kyori', 'wakuban', 'chakujun', 
                            'soha_time_sec', 'kohan_3f_sec', 'weight_kg', 'tosu'])
    df = df[df['soha_time_sec'] > 0]
    df = df[df['kohan_3f_sec'] > 0]
    df = df[df['tosu'] >= 4]
    print(f"   ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å¾Œ: {len(df):,}è¡Œ\n")
    
    return df


# ============================
# å„æŒ‡æ•°è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
# ============================

def calculate_all_indices_simple(df: pd.DataFrame) -> pd.DataFrame:
    """HQS 4æŒ‡æ•°ã‚’è¨ˆç®—ï¼ˆå®Ÿè£…æº–æ‹ ç‰ˆï¼‰"""
    print("ğŸ”¢ HQS 4æŒ‡æ•°è¨ˆç®—é–‹å§‹ï¼ˆå®Ÿè£…æº–æ‹ ç‰ˆï¼‰...")
    
    results = []
    
    for idx, row in df.iterrows():
        try:
            # åŸºæœ¬æƒ…å ±
            keibajo_code = int(row['keibajo_code'])
            kyori = int(row['kyori'])
            wakuban = int(row['wakuban'])
            tosu = int(row['tosu'])
            
            # ã‚¿ã‚¤ãƒ æƒ…å ±
            soha_time_sec = float(row['soha_time_sec'])
            kohan_3f_sec = float(row['kohan_3f_sec'])
            
            # å‰åŠ3Fæ¨å®š
            if 'actual_ten_3f' in row and pd.notna(row['actual_ten_3f']):
                zenhan_3f = float(row['actual_ten_3f'])
            else:
                zenhan_3f = soha_time_sec - kohan_3f_sec
            
            # ã‚³ãƒ¼ãƒŠãƒ¼é †ä½
            if 'corner_4' in row and pd.notna(row['corner_4']):
                corner_4 = int(row['corner_4'])
            else:
                corner_4 = int(row['chakujun']) if 'chakujun' in row else tosu // 2
            
            # åŸºæº–ã‚¿ã‚¤ãƒ ï¼ˆè·é›¢åˆ¥ï¼‰
            try:
                if kyori <= 1200:
                    base_time = 37.5
                elif kyori <= 1400:
                    base_time = 38.0
                elif kyori <= 1600:
                    base_time = 39.0
                elif kyori <= 1800:
                    base_time = 39.5
                elif kyori <= 2000:
                    base_time = 40.0
                else:  # 2000mè¶…
                    base_time = 40.5
            except:
                base_time = 39.0
            
            # 1. ãƒ†ãƒ³æŒ‡æ•°ï¼ˆTen Indexï¼‰
            ten_index = ((base_time - zenhan_3f)) * 10
            ten_index = max(-100, min(100, ten_index))
            
            # 2. ä½ç½®æŒ‡æ•°ï¼ˆPosition Indexï¼‰
            avg_position = corner_4
            base_position = tosu / 2.0
            position_index = ((base_position - avg_position) / tosu) * 100
            position_index = max(0, min(100, position_index))
            
            # 3. ä¸ŠãŒã‚ŠæŒ‡æ•°ï¼ˆAgari Indexï¼‰
            agari_index = ((base_time - kohan_3f_sec)) * 10
            agari_index = max(-100, min(100, agari_index))
            
            # 4. ãƒšãƒ¼ã‚¹æŒ‡æ•°ï¼ˆPace Indexï¼‰
            pace_index = ten_index - agari_index
            pace_index = max(-100, min(100, pace_index))
            
            results.append({
                'race_id': row['race_id'],
                'umaban': row['umaban'],
                'chakujun': row['chakujun'],
                'tosu': tosu,
                'ãƒ†ãƒ³æŒ‡æ•°': ten_index,
                'ä½ç½®æŒ‡æ•°': position_index,
                'ä¸ŠãŒã‚ŠæŒ‡æ•°': agari_index,
                'ãƒšãƒ¼ã‚¹æŒ‡æ•°': pace_index
            })
            
        except Exception as e:
            continue
    
    result_df = pd.DataFrame(results)
    print(f"   æŒ‡æ•°è¨ˆç®—å®Œäº†: {len(result_df):,}é ­\n")
    
    return result_df


# ============================
# åˆ†å¸ƒè¨ˆç®—
# ============================

def calculate_distribution(df: pd.DataFrame, index_name: str, bin_size: int) -> dict:
    """æŒ‡æ•°ã®åˆ†å¸ƒã‚’è¨ˆç®—"""
    values = df[index_name].dropna()
    
    # ç¯„å›²ã‚’æ±ºå®š
    if index_name == 'ä½ç½®æŒ‡æ•°':
        min_val = 0
        max_val = 100
    else:
        min_val = -100
        max_val = 100
    
    # ãƒ“ãƒ³ã‚’ä½œæˆ
    bins = list(range(min_val, max_val + bin_size, bin_size))
    labels = [f"{bins[i]}ï½{bins[i+1]}" for i in range(len(bins)-1)]
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
    counts, _ = np.histogram(values, bins=bins)
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¨ˆç®—
    total = len(values)
    percentages = [(count / total * 100) if total > 0 else 0 for count in counts]
    
    # çµæœã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
    distribution = []
    for i, label in enumerate(labels):
        distribution.append({
            'ç¯„å›²': label,
            'ä»¶æ•°': int(counts[i]),
            'å‰²åˆ(%)': round(percentages[i], 2)
        })
    
    return {
        'æŒ‡æ•°å': index_name,
        'åŒºåˆ‡ã‚Š': f'{bin_size}åˆ»ã¿',
        'ãƒ‡ãƒ¼ã‚¿æ•°': total,
        'åˆ†å¸ƒ': distribution
    }


def print_distribution(dist: dict):
    """åˆ†å¸ƒã‚’è¡¨ç¤º"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {dist['æŒ‡æ•°å']} ã®åˆ†å¸ƒï¼ˆ{dist['åŒºåˆ‡ã‚Š']}ï¼‰")
    print(f"{'='*80}")
    print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {dist['ãƒ‡ãƒ¼ã‚¿æ•°']:,}é ­\n")
    
    print(f"{'ç¯„å›²':>15} {'ä»¶æ•°':>12} {'å‰²åˆ(%)':>12}")
    print("-" * 80)
    
    for item in dist['åˆ†å¸ƒ']:
        print(f"{item['ç¯„å›²']:>15} {item['ä»¶æ•°']:>12,} {item['å‰²åˆ(%)']:>12.2f}")


# ============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================

def main():
    print("=" * 100)
    print("ğŸ“Š HQS 4æŒ‡æ•°ã®åˆ†å¸ƒç¢ºèªï¼ˆ10åŒºåˆ‡ã‚Šãƒ»5åŒºåˆ‡ã‚Šï¼‰")
    print("=" * 100)
    
    # å¯¾è©±å¼è¨­å®š
    data_path = input(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆç©ºç™½ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰: ").strip() or DEFAULT_DATA_PATH
    start_date = input(f"é–‹å§‹æ—¥ï¼ˆYYYYMMDDã€ç©ºç™½ã§{DEFAULT_START_DATE}ï¼‰: ").strip() or DEFAULT_START_DATE
    end_date = input(f"çµ‚äº†æ—¥ï¼ˆYYYYMMDDã€ç©ºç™½ã§{DEFAULT_END_DATE}ï¼‰: ").strip() or DEFAULT_END_DATE
    sample_rate_str = input(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡ï¼ˆ0.0ï½1.0ã€ç©ºç™½ã§{DEFAULT_SAMPLE_RATE}ï¼‰: ").strip()
    sample_rate = float(sample_rate_str) if sample_rate_str else DEFAULT_SAMPLE_RATE
    
    print("\n" + "=" * 100)
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {data_path}")
    print(f"æœŸé–“: {start_date} ï½ {end_date}")
    print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {int(sample_rate*100)}%")
    print("=" * 100 + "\n")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_and_filter_data(data_path, start_date, end_date, sample_rate)
    
    # æŒ‡æ•°è¨ˆç®—
    df_with_indices = calculate_all_indices_simple(df)
    
    # å„æŒ‡æ•°ã®åˆ†å¸ƒã‚’è¨ˆç®—
    index_names = ['ãƒ†ãƒ³æŒ‡æ•°', 'ä½ç½®æŒ‡æ•°', 'ä¸ŠãŒã‚ŠæŒ‡æ•°', 'ãƒšãƒ¼ã‚¹æŒ‡æ•°']
    
    # 10åŒºåˆ‡ã‚Š
    print("\n" + "=" * 100)
    print("ğŸ“Š 10åŒºåˆ‡ã‚Šã®åˆ†å¸ƒ")
    print("=" * 100)
    
    distributions_10 = []
    for index_name in index_names:
        dist = calculate_distribution(df_with_indices, index_name, 10)
        distributions_10.append(dist)
        print_distribution(dist)
    
    # 5åŒºåˆ‡ã‚Š
    print("\n" + "=" * 100)
    print("ğŸ“Š 5åŒºåˆ‡ã‚Šã®åˆ†å¸ƒ")
    print("=" * 100)
    
    distributions_5 = []
    for index_name in index_names:
        dist = calculate_distribution(df_with_indices, index_name, 5)
        distributions_5.append(dist)
        print_distribution(dist)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = os.path.dirname(data_path) if os.path.dirname(data_path) else '.'
    
    # 10åŒºåˆ‡ã‚Šã®çµæœã‚’ä¿å­˜
    output_data_10 = []
    for dist in distributions_10:
        for item in dist['åˆ†å¸ƒ']:
            output_data_10.append({
                'æŒ‡æ•°å': dist['æŒ‡æ•°å'],
                'ç¯„å›²': item['ç¯„å›²'],
                'ä»¶æ•°': item['ä»¶æ•°'],
                'å‰²åˆ(%)': item['å‰²åˆ(%)']
            })
    
    df_10 = pd.DataFrame(output_data_10)
    csv_path_10 = os.path.join(output_dir, 'index_distribution_10.csv')
    json_path_10 = os.path.join(output_dir, 'index_distribution_10.json')
    df_10.to_csv(csv_path_10, index=False, encoding='utf-8-sig')
    df_10.to_json(json_path_10, orient='records', force_ascii=False, indent=2)
    
    # 5åŒºåˆ‡ã‚Šã®çµæœã‚’ä¿å­˜
    output_data_5 = []
    for dist in distributions_5:
        for item in dist['åˆ†å¸ƒ']:
            output_data_5.append({
                'æŒ‡æ•°å': dist['æŒ‡æ•°å'],
                'ç¯„å›²': item['ç¯„å›²'],
                'ä»¶æ•°': item['ä»¶æ•°'],
                'å‰²åˆ(%)': item['å‰²åˆ(%)']
            })
    
    df_5 = pd.DataFrame(output_data_5)
    csv_path_5 = os.path.join(output_dir, 'index_distribution_5.csv')
    json_path_5 = os.path.join(output_dir, 'index_distribution_5.json')
    df_5.to_csv(csv_path_5, index=False, encoding='utf-8-sig')
    df_5.to_json(json_path_5, orient='records', force_ascii=False, indent=2)
    
    print("\n" + "=" * 100)
    print("âœ… çµæœä¿å­˜å®Œäº†")
    print("=" * 100)
    print(f"ã€10åŒºåˆ‡ã‚Šã€‘")
    print(f"CSV: {csv_path_10}")
    print(f"JSON: {json_path_10}")
    print(f"\nã€5åŒºåˆ‡ã‚Šã€‘")
    print(f"CSV: {csv_path_5}")
    print(f"JSON: {json_path_5}")
    print("=" * 100)
    
    input("\nâœ… HQS 4æŒ‡æ•°ã®åˆ†å¸ƒç¢ºèªå®Œäº†ï¼Enterã§çµ‚äº†...")


if __name__ == '__main__':
    main()
