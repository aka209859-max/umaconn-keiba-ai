#!/usr/bin/env python3
"""
ãƒšãƒ¼ã‚¹è£œæ­£å€¤ã®å†åˆ†æï¼ˆæ”¹ä¿®å±¥æ­´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰

ç›®çš„:
1) æ”¹ä¿®ãƒ»ç§»è»¢ã®å½±éŸ¿ã‚’é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ãƒšãƒ¼ã‚¹è£œæ­£å€¤ã‚’å†ç®—å‡º
2) å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆ+0.07ç§’ï¼‰ã¨ç†è«–å€¤ï¼ˆ-0.8ç§’ï¼‰ã®ä¹–é›¢ã‚’å†æ¤œè¨¼
3) å›åç‡åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆ2016-2025å¹´ï¼‰ã§ç²¾åº¦ã‚’ç¢ºèª

ä½œæˆæ—¥: 2026-01-10
ä½œæˆè€…: NAR-AI-YOSO Project
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from scripts.filter_by_renovation import filter_by_renovation, add_renovation_flag

# ============================
# è¨­å®š
# ============================
INPUT_CSV = '/home/user/uploaded_files/data-1768047611955.csv'
OUTPUT_DIR = Path('/home/user/webapp/nar-ai-yoso/data')
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================
print('ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...')
df = pd.read_csv(INPUT_CSV, low_memory=False, 
                 skiprows=lambda i: i > 0 and np.random.rand() > 0.1)
print(f'âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} è¡Œï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°10%ï¼‰')

# ============================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
# ============================
print('\nğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ä¸­...')

# æ•°å€¤å‹ã¸ã®å¤‰æ›
df['keibajo_code'] = pd.to_numeric(df['keibajo_code'], errors='coerce')
df['kyori'] = pd.to_numeric(df['kyori'], errors='coerce')
df['soha_time_sec'] = pd.to_numeric(df['soha_time_sec'], errors='coerce')
df['kohan_3f_sec'] = pd.to_numeric(df['kohan_3f_sec'], errors='coerce')

# ç•°å¸¸å€¤é™¤å¤–
df = df[df['kyori'].between(800, 3000)]
df = df[df['soha_time_sec'] > 0]
df = df[df['kohan_3f_sec'] > 0]

print(f'âœ… ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å®Œäº†: {len(df):,} è¡Œ')

# ============================
# å›åç‡åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã§ãƒšãƒ¼ã‚¹æ¤œè¨¼
# ============================
print('\n' + '='*60)
print('å›åç‡åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆ2016-2025å¹´ï¼‰ã§ãƒšãƒ¼ã‚¹è£œæ­£å€¤ã‚’å†æ¤œè¨¼')
print('='*60)

df_recovery = filter_by_renovation(df, purpose='recovery_rate_analysis')

# å‰åŠ3Fã‚¿ã‚¤ãƒ ã®æ¨å®š
df_recovery['zenhan_3f_estimated'] = df_recovery['soha_time_sec'] - df_recovery['kohan_3f_sec']

# ãƒšãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ï¼ˆç«¶é¦¬å ´Ã—è·é›¢åˆ¥ã®åŸºæº–å€¤ã‚’ä½¿ç”¨ï¼‰
df_recovery['keibajo_kyori'] = (
    df_recovery['keibajo_code'].astype(str) + '_' + 
    df_recovery['kyori'].astype(str)
)

zenhan_mean = df_recovery.groupby('keibajo_kyori')['zenhan_3f_estimated'].mean().to_dict()
df_recovery['zenhan_3f_mean'] = df_recovery['keibajo_kyori'].map(zenhan_mean)
df_recovery['pace_deviation'] = df_recovery['zenhan_3f_estimated'] - df_recovery['zenhan_3f_mean']

# ãƒšãƒ¼ã‚¹åˆ†é¡ï¼ˆé–¾å€¤Â±0.8ç§’ï¼‰
def classify_pace(deviation):
    if pd.isna(deviation):
        return 'M'
    elif deviation < -0.8:  # å‰åŠãŒå¹³å‡ã‚ˆã‚Š0.8ç§’ä»¥ä¸Šé€Ÿã„
        return 'H'
    elif deviation > 0.8:   # å‰åŠãŒå¹³å‡ã‚ˆã‚Š0.8ç§’ä»¥ä¸Šé…ã„
        return 'S'
    else:
        return 'M'

df_recovery['pace_type'] = df_recovery['pace_deviation'].apply(classify_pace)

# ãƒšãƒ¼ã‚¹åˆ¥ã®çµ±è¨ˆé‡
pace_stats = df_recovery.groupby('pace_type').agg({
    'kohan_3f_sec': ['mean', 'std', 'count'],
    'zenhan_3f_estimated': ['mean', 'std'],
    'soha_time_sec': ['mean', 'std']
}).round(3)

print('\nğŸ“Š ãƒšãƒ¼ã‚¹åˆ¥ã®çµ±è¨ˆé‡ï¼ˆ2016-2025å¹´ã€æ”¹ä¿®å¾Œãƒ‡ãƒ¼ã‚¿ï¼‰:')
print(pace_stats)

# ãƒšãƒ¼ã‚¹è£œæ­£å€¤ã®ç®—å‡ºï¼ˆåŸºæº–å€¤Mã¨ã®å·®åˆ†ï¼‰
m_kohan_3f = df_recovery[df_recovery['pace_type'] == 'M']['kohan_3f_sec'].mean()
h_kohan_3f = df_recovery[df_recovery['pace_type'] == 'H']['kohan_3f_sec'].mean()
s_kohan_3f = df_recovery[df_recovery['pace_type'] == 'S']['kohan_3f_sec'].mean()

h_correction = h_kohan_3f - m_kohan_3f
s_correction = s_kohan_3f - m_kohan_3f

print('\n' + '='*60)
print('ğŸ¯ ãƒšãƒ¼ã‚¹è£œæ­£å€¤ã®ç®—å‡ºçµæœï¼ˆ2016-2025å¹´ï¼‰')
print('='*60)
print(f'ãƒã‚¤ãƒšãƒ¼ã‚¹ï¼ˆHï¼‰: å¾ŒåŠ3Få·®åˆ† = {h_correction:+.3f}ç§’')
print(f'ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹ï¼ˆSï¼‰: å¾ŒåŠ3Få·®åˆ† = {s_correction:+.3f}ç§’')
print(f'\næ¯”è¼ƒ:')
print(f'  å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆå…¨æœŸé–“2005-2025å¹´ï¼‰: H {0.07:+.2f}ç§’ / S {0.40:+.2f}ç§’')
print(f'  å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆå›åæœŸé–“2016-2025å¹´ï¼‰: H {h_correction:+.3f}ç§’ / S {s_correction:+.3f}ç§’')
print(f'  ãƒ‡ã‚£ãƒ¼ãƒ—ã‚µãƒ¼ãƒç†è«–å€¤: H -0.8ç§’ / S +0.3ç§’')

# ============================
# è·é›¢åˆ¥ã®ãƒšãƒ¼ã‚¹å½±éŸ¿åˆ†æ
# ============================
print('\n' + '='*60)
print('è·é›¢åˆ¥ã®ãƒšãƒ¼ã‚¹å½±éŸ¿åˆ†æ')
print('='*60)

# è·é›¢å¸¯ã‚’åˆ†é¡
df_recovery['kyori_range'] = pd.cut(
    df_recovery['kyori'],
    bins=[0, 1400, 1800, 3000],
    labels=['çŸ­è·é›¢(<1400m)', 'ãƒã‚¤ãƒ«(1400-1800m)', 'ä¸­é•·è·é›¢(â‰¥1800m)']
)

pace_by_distance = df_recovery.groupby(['kyori_range', 'pace_type']).agg({
    'kohan_3f_sec': 'mean',
    'race_id': 'count'
}).reset_index()

pace_by_distance.columns = ['è·é›¢å¸¯', 'ãƒšãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', 'å¾ŒåŠ3Få¹³å‡', 'ã‚µãƒ³ãƒ—ãƒ«æ•°']

print('\nğŸ“Š è·é›¢åˆ¥Ã—ãƒšãƒ¼ã‚¹åˆ¥ã®å¾ŒåŠ3Få¹³å‡:')
print(pace_by_distance.pivot(index='è·é›¢å¸¯', columns='ãƒšãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', values='å¾ŒåŠ3Få¹³å‡').round(2))

print('\nğŸ“Š è·é›¢åˆ¥Ã—ãƒšãƒ¼ã‚¹åˆ¥ã®ã‚µãƒ³ãƒ—ãƒ«æ•°:')
print(pace_by_distance.pivot(index='è·é›¢å¸¯', columns='ãƒšãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', values='ã‚µãƒ³ãƒ—ãƒ«æ•°'))

# ============================
# å‡ºåŠ›
# ============================
output_csv = OUTPUT_DIR / 'pace_correction_reanalysis_2016_2025.csv'
pace_stats.to_csv(output_csv)
print(f'\nâœ… å†åˆ†æçµæœã‚’ä¿å­˜: {output_csv}')

# ============================
# çµè«–
# ============================
print('\n' + '='*60)
print('ğŸ“Š å†åˆ†æã®çµè«–')
print('='*60)
print(f'''
1. **å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆ2016-2025å¹´ã€æ”¹ä¿®å¾Œï¼‰ã®è£œæ­£å€¤**:
   - ãƒã‚¤ãƒšãƒ¼ã‚¹ï¼ˆHï¼‰: {h_correction:+.3f}ç§’ï¼ˆå‰åŠãŒé€Ÿã„â†’å¾ŒåŠãŒã‚„ã‚„é…ã„ï¼‰
   - ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹ï¼ˆSï¼‰: {s_correction:+.3f}ç§’ï¼ˆå‰åŠãŒé…ã„â†’å¾ŒåŠãŒé…ã„ï¼‰

2. **ãƒ‡ã‚£ãƒ¼ãƒ—ã‚µãƒ¼ãƒç†è«–å€¤ã¨ã®ä¹–é›¢**:
   - H: {h_correction:+.3f}ç§’ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰vs -0.8ç§’ï¼ˆç†è«–ï¼‰â†’ å·®åˆ† {h_correction - (-0.8):.3f}ç§’
   - S: {s_correction:+.3f}ç§’ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰vs +0.3ç§’ï¼ˆç†è«–ï¼‰â†’ å·®åˆ† {s_correction - 0.3:.3f}ç§’

3. **çµè«–**:
   - å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã¯ãƒšãƒ¼ã‚¹å½±éŸ¿ãŒæ¥µã‚ã¦å°ã•ã„ï¼ˆH {h_correction:+.3f}ç§’ï¼‰
   - ç†è«–å€¤ï¼ˆH -0.8ç§’ï¼‰ã¯ã€Œãƒã‚¤ãƒšãƒ¼ã‚¹æ™‚ã«å¾ŒåŠãŒé€Ÿããªã‚‹ã€ã‚’æ„å‘³ã™ã‚‹ãŒã€
     å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã¯ã€Œãƒã‚¤ãƒšãƒ¼ã‚¹æ™‚ã«å¾ŒåŠãŒé…ããªã‚‹ã€ã¨ã„ã†æ­£åå¯¾ã®å‚¾å‘
   - **ãƒšãƒ¼ã‚¹è£œæ­£ã®å®šç¾©ã¾ãŸã¯ç¬¦å·ãŒé€†è»¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„**

4. **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:
   - ãƒ‡ã‚£ãƒ¼ãƒ—ã‚µãƒ¼ãƒã§ã€Œè£œæ­£ã®æ–¹å‘æ€§ï¼ˆç¬¦å·ï¼‰ã€ã‚’å†ç¢ºèª
   - ã¾ãŸã¯ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè£œæ­£å€¤ã‚’æ¡ç”¨ï¼ˆH {h_correction:+.3f}ç§’ / S {s_correction:+.3f}ç§’ï¼‰
''')

print('\nâœ… å†åˆ†æå®Œäº†ï¼')
