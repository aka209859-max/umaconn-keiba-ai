#!/usr/bin/env python3
"""
æŒ‡æ•°æ­£è¦åŒ–å™¨ã®å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒãƒƒãƒå®Ÿè¡Œç‰ˆï¼‰

éå¯¾è©±å¼ã§ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¨­å®šã‚’å—ã‘å–ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/train_normalizers_batch.py <data_path> [sample_rate] [output_dir]

Author: AIæˆ¦ç•¥å®¶ï¼ˆNAR-AI-YOSOé–‹ç™ºãƒãƒ¼ãƒ ï¼‰
Date: 2026-01-10
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import logging
from core.index_normalizer import RacingIndexNormalizer
from core.ten_3f_estimator import Ten3FEstimator

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================
# å‰åŠ3Fæ¨å®š
# ============================

# è·é›¢æ¯”ç‡
DISTANCE_RATIOS = {
    1200: None,
    1230: 0.495,
    1300: 0.48,
    1400: 0.26,
    1500: 0.24,
    1600: 0.22,
    1700: 0.21,
    1800: 0.22,
    2000: 0.17,
    2100: 0.16
}

MIN_TEN_3F = 30.0
MAX_TEN_3F = 45.0


def get_distance_ratio(kyori: int) -> float:
    if kyori in DISTANCE_RATIOS and DISTANCE_RATIOS[kyori] is not None:
        return DISTANCE_RATIOS[kyori]
    
    if kyori <= 1200:
        return 0.50
    
    sorted_distances = sorted([k for k in DISTANCE_RATIOS.keys() if k > 1200 and DISTANCE_RATIOS[k] is not None])
    
    for i in range(len(sorted_distances) - 1):
        d1 = sorted_distances[i]
        d2 = sorted_distances[i + 1]
        
        if d1 <= kyori <= d2:
            r1 = DISTANCE_RATIOS[d1]
            r2 = DISTANCE_RATIOS[d2]
            ratio = r1 + (r2 - r1) * (kyori - d1) / (d2 - d1)
            return ratio
    
    if kyori > max(sorted_distances):
        return 0.15
    
    return 0.22


def estimate_zenhan_3f(soha_time_sec: float, kohan_3f_sec: float, kyori: int) -> float:
    if kyori < 1200:
        zenhan_3f = soha_time_sec - kohan_3f_sec
        return max(MIN_TEN_3F, min(MAX_TEN_3F, zenhan_3f))
    
    if kyori == 1200:
        zenhan_3f = soha_time_sec - kohan_3f_sec
        return max(MIN_TEN_3F, min(MAX_TEN_3F, zenhan_3f))
    
    ratio = get_distance_ratio(kyori)
    zenhan_3f = soha_time_sec * ratio
    zenhan_3f = max(MIN_TEN_3F, min(MAX_TEN_3F, zenhan_3f))
    
    return zenhan_3f


# ============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================

def load_data(file_path: str, sample_rate: float = 1.0) -> pd.DataFrame:
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {file_path}")
    logger.info(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {sample_rate * 100:.1f}%")
    
    required_cols = [
        'race_id', 'umaban', 'chakujun', 'tosu',
        'soha_time_sec', 'kohan_3f_sec', 'kyori',
        'race_date', 'keibajo_code',
        'corner_1', 'corner_2', 'corner_3', 'corner_4'
    ]
    
    if sample_rate < 1.0:
        df = pd.read_csv(
            file_path,
            usecols=lambda col: col in required_cols,
            skiprows=lambda i: i > 0 and np.random.random() > sample_rate
        )
    else:
        df = pd.read_csv(file_path, usecols=required_cols)
    
    logger.info(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}è¡Œ")
    
    # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ2023/10/13ä»¥é™ï¼‰
    df = df[df['race_date'] >= 20231013]
    logger.info(f"æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df):,}è¡Œ")
    
    # ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    df = df.dropna(subset=['soha_time_sec', 'kohan_3f_sec', 'kyori', 'tosu'])
    df = df[df['soha_time_sec'] > 0]
    df = df[df['kohan_3f_sec'] > 0]
    df = df[df['tosu'] >= 4]
    
    logger.info(f"ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å¾Œ: {len(df):,}è¡Œ")
    
    return df


# ============================
# æŒ‡æ•°è¨ˆç®—
# ============================

def calculate_indices(df: pd.DataFrame) -> pd.DataFrame:
    """æŒ‡æ•°ã‚’è¨ˆç®—"""
    logger.info("æŒ‡æ•°è¨ˆç®—é–‹å§‹...")
    
    results = []
    
    for idx, row in df.iterrows():
        try:
            soha_time_sec = float(row['soha_time_sec'])
            kohan_3f_sec = float(row['kohan_3f_sec'])
            kyori = int(row['kyori'])
            tosu = int(row['tosu'])
            
            # å‰åŠ3Fæ¨å®š
            zenhan_3f = estimate_zenhan_3f(soha_time_sec, kohan_3f_sec, kyori)
            
            # ã‚³ãƒ¼ãƒŠãƒ¼4è§’
            if 'corner_4' in row and pd.notna(row['corner_4']):
                corner_4 = int(row['corner_4'])
            else:
                corner_4 = int(row['chakujun']) if 'chakujun' in row else tosu // 2
            
            # åŸºæº–ã‚¿ã‚¤ãƒ 
            if kyori <= 1200:
                base_time = 37.5
            elif kyori <= 1400:
                base_time = 38.0
            elif kyori <= 1600:
                base_time = 39.0
            elif kyori <= 1800:
                base_time = 39.5
            elif kyori <= 2000:
                base_time = 40.0
            else:
                base_time = 40.5
            
            # æŒ‡æ•°è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼šè£œæ­£ãªã—ï¼‰
            agari_index = base_time - kohan_3f_sec
            ten_index = base_time - zenhan_3f
            
            avg_position = corner_4
            base_position = tosu / 2.0
            position_index = ((base_position - avg_position) / tosu) * 100
            position_index = max(0, min(100, position_index))
            
            pace_index = (ten_index + agari_index) / 2
            
            results.append({
                'ten_index': ten_index,
                'agari_index': agari_index,
                'position_index': position_index,
                'pace_index': pace_index
            })
            
        except Exception as e:
            continue
    
    result_df = pd.DataFrame(results)
    logger.info(f"æŒ‡æ•°è¨ˆç®—å®Œäº†: {len(result_df):,}ä»¶")
    
    return result_df


# ============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("="*60)
    logger.info("NAR-SI3.0 æŒ‡æ•°æ­£è¦åŒ–å™¨ å­¦ç¿’ï¼ˆãƒãƒƒãƒç‰ˆï¼‰")
    logger.info("="*60)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python train_normalizers_batch.py <data_path> [sample_rate] [output_dir]")
        sys.exit(1)
    
    data_path = sys.argv[1]
    sample_rate = float(sys.argv[2]) if len(sys.argv) > 2 else 0.1
    output_dir = sys.argv[3] if len(sys.argv) > 3 else 'models/normalizers'
    
    logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {data_path}")
    logger.info(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: {sample_rate * 100:.1f}%")
    logger.info(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_data(data_path, sample_rate)
    
    if len(df) == 0:
        logger.error("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: æŒ‡æ•°è¨ˆç®—
    index_df = calculate_indices(df)
    
    if len(index_df) == 0:
        logger.error("æŒ‡æ•°è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: æ­£è¦åŒ–å™¨ã®å­¦ç¿’
    logger.info("\n" + "="*60)
    logger.info("æ­£è¦åŒ–å™¨ã®å­¦ç¿’é–‹å§‹")
    logger.info("="*60)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ãƒ†ãƒ³æŒ‡æ•°
    logger.info("\nãƒ†ãƒ³æŒ‡æ•°ã®æ­£è¦åŒ–å™¨ã‚’å­¦ç¿’ä¸­...")
    ten_normalizer = RacingIndexNormalizer()
    ten_normalizer.fit(index_df['ten_index'].values)
    ten_path = os.path.join(output_dir, 'ten_index_normalizer.pkl')
    ten_normalizer.save(ten_path)
    logger.info(f"ä¿å­˜å®Œäº†: {ten_path}")
    
    # ä¸ŠãŒã‚ŠæŒ‡æ•°
    logger.info("\nä¸ŠãŒã‚ŠæŒ‡æ•°ã®æ­£è¦åŒ–å™¨ã‚’å­¦ç¿’ä¸­...")
    agari_normalizer = RacingIndexNormalizer()
    agari_normalizer.fit(index_df['agari_index'].values)
    agari_path = os.path.join(output_dir, 'agari_index_normalizer.pkl')
    agari_normalizer.save(agari_path)
    logger.info(f"ä¿å­˜å®Œäº†: {agari_path}")
    
    # ä½ç½®æŒ‡æ•°
    logger.info("\nä½ç½®æŒ‡æ•°ã®æ­£è¦åŒ–å™¨ã‚’å­¦ç¿’ä¸­...")
    position_normalizer = RacingIndexNormalizer(target_range=(0, 100))
    position_normalizer.fit(index_df['position_index'].values)
    position_path = os.path.join(output_dir, 'position_index_normalizer.pkl')
    position_normalizer.save(position_path)
    logger.info(f"ä¿å­˜å®Œäº†: {position_path}")
    
    # ãƒšãƒ¼ã‚¹æŒ‡æ•°
    logger.info("\nãƒšãƒ¼ã‚¹æŒ‡æ•°ã®æ­£è¦åŒ–å™¨ã‚’å­¦ç¿’ä¸­...")
    pace_normalizer = RacingIndexNormalizer()
    pace_normalizer.fit(index_df['pace_index'].values)
    pace_path = os.path.join(output_dir, 'pace_index_normalizer.pkl')
    pace_normalizer.save(pace_path)
    logger.info(f"ä¿å­˜å®Œäº†: {pace_path}")
    
    # å®Œäº†
    logger.info("\n" + "="*60)
    logger.info("âœ… å…¨ã¦ã®æ­£è¦åŒ–å™¨ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    logger.info("="*60)
    logger.info(f"\nå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    logger.info(f"  - {ten_path}")
    logger.info(f"  - {agari_path}")
    logger.info(f"  - {position_path}")
    logger.info(f"  - {pace_path}")
    
    logger.info("\nğŸ† Play to Win!")


if __name__ == '__main__':
    main()
